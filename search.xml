<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Transformer学习笔记</title>
      <link href="/2023/09/03/study/transformer/"/>
      <url>/2023/09/03/study/transformer/</url>
      
        <content type="html"><![CDATA[<font size=8><center>Transformer系列算法学习</center></font><h1 id="原始Transformer"><a href="#原始Transformer" class="headerlink" title="原始Transformer"></a>原始Transformer</h1><h1 id="Transformer改进"><a href="#Transformer改进" class="headerlink" title="Transformer改进"></a>Transformer改进</h1><h1 id="CV-former"><a href="#CV-former" class="headerlink" title="CV-former"></a>CV-former</h1><h1 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h1><h1 id="SAM"><a href="#SAM" class="headerlink" title="SAM"></a>SAM</h1><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二十二</title>
      <link href="/2023/06/15/life/birth22/"/>
      <url>/2023/06/15/life/birth22/</url>
      
        <content type="html"><![CDATA[<font size=6><center>二  十  二</center></font><p>2023.6.1，22岁<br>今天已经是6.15了，才空下来补一个blog，只能说这一年确实挺忙的。<br>还是和去年一样，按顺序总结一下吧。</p><p>6月印象：。。。<br>咋没啥印象 :joy:<br>哦哦，不对，进组接触了一丁点东西<br><br/></p><p>7月印象：回家 + new PC<br>旧电脑退休了<br>我又开始长肉了<br><br/></p><p>8月印象：开学 + 添置设备<br>换了新电脑，那为了能更好的搞(da)学(you)习(xi)，直接宿舍显示器啥的配置好 :grin:<br><br/></p><p>9月印象：爽玩 + 正式进组 + 保研面试<br>大四嘛，肯定先爽吃、爽喝、爽玩！</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/P2T5Dj4hQ7VAqkn.jpg" width = "60%" align = center/></center><p>正式进实验室<a href="https://lightzh.cc/2022/09/15/life/study_anomaly/">学(ban)习(zhuan)</a>了</p><p>面试挺轻松的！！！<br><br/></p><p>10月印象：做实验 + 校庆餐<br>一个月都在学代码、做数据集、跑实验，但效果不佳。</p><p>校庆吃了个校庆餐，怎么说呢，只能说不要钱就好 :sweat:<br><br/></p><p>11月印象：大学最后一门考试 + 实验成功啦<br>首先大四还有一门课属实是。。。考完就好。</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/yzmC9LqJEsgefv4.jpg" width = "60%" align = center/></center><p>终于，我把实验跑通了，而且效果还不错！<br><br/></p><p>12月印象：提前回家 + 还是:sheep:了<br>放开了，也提前回家了</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/pkb1yWXoSjfQ4g9.jpg" width = "60%" align = center/></center>路上防护得挺好的，以为躲过了，但在家还是中招了1月印象：寒假 + 过年回家还是写小论文了！今年的酒喝得有点多！2月印象：开学 + :frog:开学了，但还想吃好的也不知道咋地，专吃:cow: :frog:对了，老板又安排了个新项目，开始学吧。3月印象：北京出差 + 赶论文实验室项目去北京出差，第一次去了北大<center class = "half"><img src = "https://s2.loli.net/2023/06/15/KpbvYTR821oPDM5.jpg" width = "60%" align = center/></center><p>终于，在3月31号完成了小论文！</p><p>4月印象：回家了 + 去长沙 + 投论文<br>清明节回家请假回家待了几天，回武汉顺便留长沙玩了几天<br>hin不戳</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/EWxZw9JTGyehIib.jpg" width = "60%" align = center/></center>爽玩一周，开始修改论文了，感谢师兄和ChatGPT4.14 论文投出去了<center class = "half"><img src = "https://s2.loli.net/2023/06/15/RQnwc8t3mWVuesJ.png" width = "60%" align = center/></center><p>啊对，大学认识了一群:basketball:友，一起打了个AIA杯，遗憾止步8强。</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/HZmVgqIcrCD3vGx.jpg" width = "60%" align = center/></center><p>5月印象：五一出差 + 答辩结束 + 襄阳游<br>劳动节出差？？<br>其实还不错，事不是很多，当作旅了个游吧</p><p>论文投出去就开始写毕设论文了，写了好几版，还好，答辩过的比较顺利，小组第一。<br>奖励，吃顿好的。</p><p>评上优秀毕设啦！<br>这不更得奖励一下自己，直接出去玩。</p><p>去了襄阳，看了唐城、古城墙、古隆中，吃了虾子、牛肉面</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/bE5UoDxnAqVRCm7.jpg" width = "60%" align = center/></center><p>对了，还打了个3v3篮球赛毕业杯，NO.2<br>只能借个奖杯来拍个照</p><center class = "half"><img src = "https://s2.loli.net/2023/06/15/mnHdCqVLtRG456l.jpg" width = "60%" align = center/></center><p>OK，这一年又写完了，这时间确实过得有点快，转眼大学也马上毕业了，怎么说呢，每一年都好好过吧！！<br>OK，就这样！！</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 记录， 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测算法学习</title>
      <link href="/2023/05/23/study/object%20detection/"/>
      <url>/2023/05/23/study/object%20detection/</url>
      
        <content type="html"><![CDATA[<font size=8><center>目标检测方法</center></font><h1 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h1><p>分类、定位、检测、分割、</p><h1 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h1><p>传统、基于深度学习</p><h1 id="基于深度学习方法"><a href="#基于深度学习方法" class="headerlink" title="基于深度学习方法"></a>基于深度学习方法</h1><p>Anchor-Based、Anchor-Free方法，其区别是是否使用Anchor进行训练和预测.<br>Anchor-based方法则包括Two stage和One stage算法，Anchor-Free算法近几年逐步完善。</p><ul><li>候选区域产生（滑窗法、选择搜索法）</li><li>交互比（IoU）评估效果</li><li>非极大抑制（NMS）<blockquote><p>疑问：<br>NMS操作时需要和真实框作IoU，是否只在训练时使用，测试时仅作指标评估？</p><h2 id="Anchor-based：Two-stage"><a href="#Anchor-based：Two-stage" class="headerlink" title="Anchor-based：Two stage"></a>Anchor-based：Two stage</h2><p>主要思想和区别：进行区域生成（region proposal-RP）<br>特征提取→生成RP→分类/定位回归<br>常见方法：R-CNN系列</p></blockquote></li></ul><h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><p>Rich feature hierarchies for accurate object detection and semantic segmentation (CVPR2014)<br><a href="https://arxiv.org/abs/1311.2524">paper</a></p><div align="center"><img src="https://s2.loli.net/2023/05/23/FqZjBYpoeDnQJbd.png" width="75%"></div><p>3个模块：</p><ol><li>RP（SS-选择性搜索，2000个RP）</li><li>CNN（AlexNet）</li><li>SVM（线性分类）</li></ol><p>缺点：</p><ol><li>速度慢</li><li>计算冗余，过程繁琐</li><li>空间消耗大</li></ol><h3 id="SPPNet"><a href="#SPPNet" class="headerlink" title="SPPNet"></a>SPPNet</h3><p>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition (TPAMI)<br><a href="https://arxiv.org/abs/1406.4729">paper</a></p><div align="center"><img src="https://s2.loli.net/2023/08/19/OENBsPQJen9KA42.png" width="75%"></div><p>核心思想：<br>在最后一层卷积层和全连接层之间引入空间金字塔池化层是SPPNet，主要目的是对于任意尺寸的输入产生固定大小的输出。</p><p><a href="https://zhuanlan.zhihu.com/p/60919662">参考</a><br>思路是对于任意大小的feature map首先分成16、4、1个块，然后在每个块上最大池化，池化后的特征拼接得到一个固定维度的输出，以满足全连接层的需要。</p><p>当使用SPPNet网络用于目标检测时，整个图像只需计算一次即可生成相应特征图，不管候选框尺寸如何，经过SPP之后，都能生成固定尺寸的特征表示图，这避免了卷积特征图的重复计算。</p><p>先提取特征再进行区域选择！</p><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>Fast R-CNN (ICCV 2015)<br><a href="https://arxiv.org/abs/1504.08083">paper</a></p><div align="center"><img src="https://s2.loli.net/2023/08/19/aZ5vqP1QTMj6ROc.png" width="75%"></div><p>与R-CNN和SPP-Net相同：</p><ol><li>同样使用SS获取RP</li><li>直接原图进行特征提取实现特征图共享，在特征图中找到每一个RP对应的区域并截取特征图中的RP，用一个单层的SSP layer来统一到一样的尺度(ROI pooling)</li></ol><p>改进优势：</p><ol><li>⽹络末尾采⽤并⾏的不同的全连接层，可同时输出分类结果和窗⼝回归结果， 实现了end-to-end的多任务训练。</li><li>直接将CNN、分类器、边界框回归器整合到一个网络，将原来三个模型整合到一个网络，便于训练，极大地提高了训练的速度。</li><li>不需要存储中间特征向量用于SVM分类和回归模型训练</li><li>训练可以更新所有层的参数</li><li>所有的训练任务是单阶段完成的，使用multi-task loss(分类损失+框回归损失)</li></ol><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (NIPS2015)<br><a href="https://arxiv.org/abs/1506.01497">paper</a></p><div align="center"><img src="https://s2.loli.net/2023/08/20/CYjnMAI86qsXlDB.png" width="75%"></div><p>改进优势：</p><ol><li>使用RPN网络代替选择性搜索(SS)进行候选区域的提取</li><li>RPN的输入是最初经过卷积生成的特征图，与后续RoI pooling共享，节省时间；输出为一组矩形目标推荐框的一个概率值和四个坐标值和每个目标推荐框含有目标的概率值</li><li>RPN网络将候选区域的提取任务建模为二分类（是否为物体）的问题，通过softmax判断anchors属于positive还是negative，再利用边界框回归修正anchors获得精确的推荐框proposals。<h2 id="Anchor-based：One-stage"><a href="#Anchor-based：One-stage" class="headerlink" title="Anchor-based：One stage"></a>Anchor-based：One stage</h2></li></ol><h2 id="Anchor-Free"><a href="#Anchor-Free" class="headerlink" title="Anchor-Free"></a>Anchor-Free</h2>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue学习</title>
      <link href="/2023/03/16/study/vue/"/>
      <url>/2023/03/16/study/vue/</url>
      
        <content type="html"><![CDATA[<h1 id="学习记录"><a href="#学习记录" class="headerlink" title="学习记录"></a>学习记录</h1><p>三种创建方式：</p><ul><li>vue init webpack mytest</li><li>npm init vite-app mytest</li><li>npm init vite@latest mytest — —template vue<h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2>可更改值并实时响应（加<code>.value</code>）<h2 id="计算属性"><a href="#计算属性" class="headerlink" title="计算属性"></a>计算属性</h2>computed<h2 id="监听属性"><a href="#监听属性" class="headerlink" title="监听属性"></a>监听属性</h2>watch<br>watchEffect：可进行数据请求<h2 id="组件传递属性"><a href="#组件传递属性" class="headerlink" title="组件传递属性"></a>组件传递属性</h2>从上到下：<code>defineProps(&#123;&#125;)</code><br>需要在低级组件修改传递属性时需要重新定义值来接受传递的属性：<code>const props = defineProps(&#123;&#125;)</code><h2 id="生命周期钩子"><a href="#生命周期钩子" class="headerlink" title="生命周期钩子"></a>生命周期钩子</h2>onMounted：页面渲染之前执行，可进行数据请求<br>onUnmounted：组件注销之前执行，执行完组件不再显示，可销毁一些对象<br>onUpdatee：组件内容发生变化时执行<h2 id="数据模拟"><a href="#数据模拟" class="headerlink" title="数据模拟"></a>数据模拟</h2></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="Header-vue"><a href="#Header-vue" class="headerlink" title="Header.vue"></a>Header.vue</h2><ul><li>data_theme 自定义了？？<h2 id="socket-js、store-js"><a href="#socket-js、store-js" class="headerlink" title="socket.js、store.js"></a>socket.js、store.js</h2></li><li>语法不清晰</li><li>流程不清楚<h2 id="tailwindcss"><a href="#tailwindcss" class="headerlink" title="tailwindcss"></a>tailwindcss</h2></li><li>许多参数代表什么不清晰，每次都要查一遍<h2 id="Console、Visualizer"><a href="#Console、Visualizer" class="headerlink" title="Console、Visualizer"></a>Console、Visualizer</h2></li><li>和后端、<code>socket.js</code>、<code>store.js</code>联系大的文件都看不大懂，只能将界面看懂，具体实现看不大懂</li></ul><h1 id="软件想法"><a href="#软件想法" class="headerlink" title="软件想法"></a>软件想法</h1><ul><li>中英对比</li><li>搜索系统</li><li>适配多样设备</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前端学习</title>
      <link href="/2023/03/16/study/web/"/>
      <url>/2023/03/16/study/web/</url>
      
        <content type="html"><![CDATA[<h1 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h1>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python简单图像处理</title>
      <link href="/2023/03/08/study/image/"/>
      <url>/2023/03/08/study/image/</url>
      
        <content type="html"><![CDATA[<h1 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h1><p>OpenCV：OpenCV是一个广泛使用的计算机视觉库，可以进行图像处理、计算机视觉、机器学习等多种任务。</p><ul><li>下载扩展包<br><code>pip install opencv-python</code></li><li>导入<br><code>import cv2</code></li><li>读取图像<br><code>cv2.imread(filepath, flags)</code><br>filepath：图像的完整路径<br>flags：读入图片的标志<blockquote><p>cv2.IMREAD_COLOR：默认参数，读入彩色图像，忽略alpha通道（透明度）<br>cv2.IMREAD_GRAYSCALE：读入灰度图像<br>cv2.IMREAD_UNCHANGED：读入完整图像，包括alpha通道</p></blockquote></li><li>显示图像<br><code>cv2.imshow(win_name, img)</code><h1 id="PIL"><a href="#PIL" class="headerlink" title="PIL"></a>PIL</h1>PIL：PIL是一个Python图像处理库，可以用于图像的读取、处理、保存等操作。<h1 id="scikit-image"><a href="#scikit-image" class="headerlink" title="scikit-image"></a>scikit-image</h1>scikit-image：scikit-image是一个基于NumPy的图像处理库，提供了多种常用的图像处理算法和工具，如图像滤波、形态学处理、图像分割、特征提取等。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码学习</title>
      <link href="/2022/09/30/study/code/"/>
      <url>/2022/09/30/study/code/</url>
      
        <content type="html"><![CDATA[<p>实现代码过程中的一些小demo，之后可能会使用到，记录一下。</p><h2 id="一、数据集制作"><a href="#一、数据集制作" class="headerlink" title="一、数据集制作"></a>一、数据集制作</h2><p>1、分类同一文件夹中不同后缀名的文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分后以txt格式存储</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split</span>(<span class="params">src</span>):</span><br><span class="line">    imges = []  <span class="comment"># 存储所有图片的路径</span></span><br><span class="line">    annotation = []  <span class="comment"># 存储所有xml的路径</span></span><br><span class="line">    <span class="comment"># 第一步：遍历需要分离的文件夹</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(src):</span><br><span class="line">        f = os.path.join(src, f)</span><br><span class="line">        <span class="keyword">if</span> f.endswith(<span class="string">&quot;.jpg&quot;</span>):  <span class="comment"># 可以是.jpg,.png,.jpeg等等</span></span><br><span class="line">            imges.append(f)</span><br><span class="line">        <span class="keyword">if</span> f.endswith(<span class="string">&quot;.xml&quot;</span>):  <span class="comment"># 可以是json文件或者xml文件</span></span><br><span class="line">            annotation.append(f)</span><br><span class="line">    <span class="keyword">return</span> imges, annotation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分之后copy到指定文件夹</span></span><br><span class="line"><span class="comment"># def split(src, img, annota):</span></span><br><span class="line"><span class="comment">#     imges = []  # 存储所有图片的路径</span></span><br><span class="line"><span class="comment">#     annotation = []  # 存储所有xml的路径</span></span><br><span class="line"><span class="comment">#     # 第一步：遍历需要分离的文件夹</span></span><br><span class="line"><span class="comment">#     for f in os.listdir(src):</span></span><br><span class="line"><span class="comment">#         f = os.path.join(src, f)</span></span><br><span class="line"><span class="comment">#         if f.endswith(&quot;.jpg&quot;):  # 可以是.jpg,.png,.jpeg等等</span></span><br><span class="line"><span class="comment">#             imges.append(f)</span></span><br><span class="line"><span class="comment">#         if f.endswith(&quot;.xml&quot;):  # 可以是json文件或者xml文件</span></span><br><span class="line"><span class="comment">#             annotation.append(f)</span></span><br><span class="line"><span class="comment"># # 第二步：创建目标图片文件夹和xml文件夹</span></span><br><span class="line"><span class="comment"># if not os.path.isdir(img):  # 如果目标图片文件夹不存在</span></span><br><span class="line"><span class="comment">#     os.mkdir(img)</span></span><br><span class="line"><span class="comment"># if not os.path.isdir(annota):  # 如果目标xml文件夹不存在</span></span><br><span class="line"><span class="comment">#     os.mkdir(annota)</span></span><br><span class="line"><span class="comment"># # 第三步：转移到目标文件夹中</span></span><br><span class="line"><span class="comment"># for im in imges:  # 遍历所有的图片，将图片文件转移到目标文件夹中</span></span><br><span class="line"><span class="comment">#     new_path = os.path.join(src, im)</span></span><br><span class="line"><span class="comment">#     # print(new_path)</span></span><br><span class="line"><span class="comment">#     shutil.copy(new_path, img)</span></span><br><span class="line"><span class="comment"># for ann in annotation:  # 遍历所有的xml,将xml文件转移到目标文件夹中</span></span><br><span class="line"><span class="comment">#     new_path = os.path.join(src, ann)</span></span><br><span class="line"><span class="comment">#     # print(new_path)</span></span><br><span class="line"><span class="comment">#     shutil.copy(new_path, annota)</span></span><br><span class="line"><span class="comment"># return imges, annotation</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_txt</span>(<span class="params">path, flod, data_list</span>):</span><br><span class="line">    f = <span class="built_in">open</span>(os.path.join(path, (flod + <span class="string">&quot;.txt&quot;</span>)), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> fp <span class="keyword">in</span> data_list:</span><br><span class="line">        f.write(<span class="built_in">str</span>(fp))</span><br><span class="line">        f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    src = <span class="string">&#x27;F:/APP/Pycharm/data/insulator&#x27;</span></span><br><span class="line">    image, annotation = split(os.path.join(src, <span class="string">&quot;images&quot;</span>))  <span class="comment"># 存放的图片路径</span></span><br><span class="line">    image_test, annotation_test = split(os.path.join(src, <span class="string">&quot;images_test&quot;</span>))  <span class="comment"># 存放的图片路径</span></span><br><span class="line">    image_all = image + image_test</span><br><span class="line">    annotation_all = annotation + annotation_test</span><br><span class="line">    write_txt(src, <span class="string">&quot;image&quot;</span>, image)</span><br><span class="line">    write_txt(src, <span class="string">&quot;image_test&quot;</span>, image_test)</span><br><span class="line">    write_txt(src, <span class="string">&quot;image_all&quot;</span>, image_all)</span><br><span class="line">    write_txt(src, <span class="string">&quot;annotation&quot;</span>, annotation)</span><br><span class="line">    write_txt(src, <span class="string">&quot;annotation_test&quot;</span>, annotation_test)</span><br><span class="line">    write_txt(src, <span class="string">&quot;annotation_all&quot;</span>, annotation_all)</span><br></pre></td></tr></table></figure></p><p>2、图像按标注可视化并裁剪<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rotateImage</span>(<span class="params">img, degree, pt1, pt2, pt3, pt4</span>):</span><br><span class="line">    height, width = img.shape[:<span class="number">2</span>]</span><br><span class="line">    heightNew = <span class="built_in">int</span>(width * fabs(sin(radians(degree))) + height * fabs(cos(radians(degree))))</span><br><span class="line">    widthNew = <span class="built_in">int</span>(height * fabs(sin(radians(degree))) + width * fabs(cos(radians(degree))))</span><br><span class="line">    matRotation = cv2.getRotationMatrix2D((width / <span class="number">2</span>, height / <span class="number">2</span>), degree, <span class="number">1</span>)</span><br><span class="line">    matRotation[<span class="number">0</span>, <span class="number">2</span>] += (widthNew - width) / <span class="number">2</span></span><br><span class="line">    matRotation[<span class="number">1</span>, <span class="number">2</span>] += (heightNew - height) / <span class="number">2</span></span><br><span class="line">    imgRotation = cv2.warpAffine(img, matRotation, (widthNew, heightNew), borderValue=(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>))</span><br><span class="line">    pt1 = <span class="built_in">list</span>(pt1)</span><br><span class="line">    pt3 = <span class="built_in">list</span>(pt3)</span><br><span class="line">    [[pt1[<span class="number">0</span>]], [pt1[<span class="number">1</span>]]] = np.dot(matRotation, np.array([[pt1[<span class="number">0</span>]], [pt1[<span class="number">1</span>]], [<span class="number">1</span>]]))</span><br><span class="line">    [[pt3[<span class="number">0</span>]], [pt3[<span class="number">1</span>]]] = np.dot(matRotation, np.array([[pt3[<span class="number">0</span>]], [pt3[<span class="number">1</span>]], [<span class="number">1</span>]]))</span><br><span class="line">    imgOut = imgRotation[<span class="built_in">int</span>(pt1[<span class="number">1</span>]):<span class="built_in">int</span>(pt3[<span class="number">1</span>]), <span class="built_in">int</span>(pt1[<span class="number">0</span>]):<span class="built_in">int</span>(pt3[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment"># imgOut = cv2.resize(imgOut, (330, 220))</span></span><br><span class="line">    cv2.imshow(<span class="string">&quot;imgOut&quot;</span>, imgOut)  <span class="comment"># 裁减得到的旋转矩形框</span></span><br><span class="line">    cv2.imwrite(<span class="string">&quot;imgOut.jpg&quot;</span>, imgOut)</span><br><span class="line">    <span class="comment"># pt2 = list(pt2)</span></span><br><span class="line">    <span class="comment"># pt4 = list(pt4)</span></span><br><span class="line">    <span class="comment"># [[pt2[0]], [pt2[1]]] = np.dot(matRotation, np.array([[pt2[0]], [pt2[1]], [1]]))</span></span><br><span class="line">    <span class="comment"># [[pt4[0]], [pt4[1]]] = np.dot(matRotation, np.array([[pt4[0]], [pt4[1]], [1]]))</span></span><br><span class="line">    <span class="comment"># pt1 = (int(pt1[0]), int(pt1[1]))</span></span><br><span class="line">    <span class="comment"># pt2 = (int(pt2[0]), int(pt2[1]))</span></span><br><span class="line">    <span class="comment"># pt3 = (int(pt3[0]), int(pt3[1]))</span></span><br><span class="line">    <span class="comment"># pt4 = (int(pt4[0]), int(pt4[1]))</span></span><br><span class="line">    <span class="comment"># drawRect(imgRotation,pt1,pt2,pt3,pt4,(255,0,0),2)</span></span><br><span class="line">    <span class="keyword">return</span> imgRotation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drawRect</span>(<span class="params">img, pt1, pt2, pt3, pt4, color, lineWidth</span>):</span><br><span class="line">    cv2.line(img, pt1, pt2, color, lineWidth)</span><br><span class="line">    cv2.line(img, pt2, pt3, color, lineWidth)</span><br><span class="line">    cv2.line(img, pt3, pt4, color, lineWidth)</span><br><span class="line">    cv2.line(img, pt1, pt4, color, lineWidth)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    startTime = time.time()</span><br><span class="line">    imgSrc = cv2.imread(<span class="string">&#x27;F:/APP/Pycharm/data/insulator/images/001501928_K1590435_10000020_1_06.jpg&#x27;</span>)</span><br><span class="line">    box = [(<span class="number">2675</span>, <span class="number">1706</span>), (<span class="number">435</span>, <span class="number">1333</span>), <span class="number">1.0646727181613587</span> * <span class="number">180</span> / np.pi]</span><br><span class="line">    contours = (cv2.boxPoints(box) / <span class="number">10</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    imgResize = cv2.resize(imgSrc, (<span class="number">660</span>, <span class="number">440</span>))</span><br><span class="line">    <span class="comment"># pt1 = (1987 / 10, 1839 / 10)</span></span><br><span class="line">    <span class="comment"># pt2 = (3152 / 10, 1193 / 10)</span></span><br><span class="line">    <span class="comment"># pt3 = (3363 / 10, 1573 / 10)</span></span><br><span class="line">    <span class="comment"># pt4 = (2198 / 10, 2220 / 10)</span></span><br><span class="line">    <span class="comment"># drawret(imgResize, contours[0], contours[1], contours[2], contours[3], (0, 0, 255), 2)</span></span><br><span class="line">    imgRotation = rotateImage(imgResize, -degrees(atan2(<span class="number">50</span>, <span class="number">50</span>)), contours[<span class="number">0</span>], contours[<span class="number">1</span>], contours[<span class="number">2</span>], contours[<span class="number">3</span>])</span><br><span class="line">    endTime = time.time()</span><br><span class="line">    <span class="built_in">print</span>(endTime - startTime)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;imgRotation&quot;</span>, imgRotation)</span><br><span class="line">    cv2.imwrite(<span class="string">&quot;imgRotation.jpg&quot;</span>, imgRotation)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><br>此代码有一点问题，有时间再修改，可以使用下面的代码</p><p>3、图像按标注裁剪<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">suofang</span>(<span class="params">im,target_height,target_width</span>):</span><br><span class="line">    height, width = im.shape[:<span class="number">2</span>]  <span class="comment"># 取彩色图片的长、宽。</span></span><br><span class="line">    ratio_h = height / target_height</span><br><span class="line">    ration_w = width / target_width</span><br><span class="line">    ratio = <span class="built_in">max</span>(ratio_h, ration_w)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 缩放图像  resize(...,size)--size(width，height)</span></span><br><span class="line">    size = (<span class="built_in">int</span>(width / ratio), <span class="built_in">int</span>(height / ratio))</span><br><span class="line">    shrink = cv2.resize(im, size, interpolation=cv2.INTER_AREA)  <span class="comment"># 双线性插值</span></span><br><span class="line">    BLACK = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    a = (target_width - <span class="built_in">int</span>(width / ratio)) / <span class="number">2</span></span><br><span class="line">    b = (target_height - <span class="built_in">int</span>(height / ratio)) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    constant = cv2.copyMakeBorder(shrink, <span class="built_in">int</span>(b), <span class="built_in">int</span>(b), <span class="built_in">int</span>(a), <span class="built_in">int</span>(a), cv2.BORDER_CONSTANT, value=BLACK)</span><br><span class="line">    constant = cv2.resize(constant, (target_width, target_height), interpolation=cv2.INTER_AREA)</span><br><span class="line">    <span class="keyword">return</span> constant</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    startTime = time.time()</span><br><span class="line">    img = cv2.imread(<span class="string">&#x27;F:/APP/Pycharm/data/insulator/crop/1.jpg&#x27;</span>)</span><br><span class="line">    h, w, c = img.shape</span><br><span class="line">    row = w <span class="keyword">if</span> w &gt; h <span class="keyword">else</span> h</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)  <span class="comment"># 有个别图片是32位ARGB的，不去除透明通道的话填充边缘的会是白色的</span></span><br><span class="line">    image = suofang(img, <span class="number">224</span>, <span class="number">224</span>)  <span class="comment"># 自己改大小</span></span><br><span class="line">    endTime = time.time()</span><br><span class="line">    <span class="built_in">print</span>(endTime - startTime)</span><br><span class="line">    <span class="comment"># cv2.imshow(&quot;imgRotation&quot;, image)</span></span><br><span class="line">    cv2.imwrite(<span class="string">&quot;imgRotation.jpg&quot;</span>, image)</span><br><span class="line">    cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p>4、解压<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unzip</span>(<span class="params">zip_file, root</span>):</span><br><span class="line">    <span class="comment"># file_path 为zip文件的全路径</span></span><br><span class="line">    <span class="comment"># root 为解压后的路径</span></span><br><span class="line">    <span class="keyword">if</span> zip_file.endswith(<span class="string">&quot;.zip&quot;</span>):</span><br><span class="line">        <span class="comment"># 判断文件的结尾是否为zip结尾</span></span><br><span class="line">        fz = zipfile.ZipFile(zip_file, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> fz.namelist():</span><br><span class="line">            fz.extract(file, root)</span><br><span class="line">        fz.close()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">fr&quot;<span class="subst">&#123;zip_file&#125;</span> this is not zip&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># zip_src源文件夹</span></span><br><span class="line">    <span class="comment"># dst_dir目标文件夹</span></span><br><span class="line">    zip_src = <span class="string">&quot;G:/insulator/xxx.zip&quot;</span></span><br><span class="line">    dst_dir = <span class="string">&quot;G:/insulator/insulator1&quot;</span></span><br><span class="line">    unzip(zip_src, dst_dir)</span><br></pre></td></tr></table></figure></p><h2 id="读改MAE代码"><a href="#读改MAE代码" class="headerlink" title="读改MAE代码"></a>读改MAE代码</h2><p>1、<code>parse_args()</code>函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立解析对象</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给parser实例添加属性</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;-gpu&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;use gpu or not&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-bs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">128</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size for dataloader&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-epoches&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">15</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size for dataloader&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把刚才的属性给args实例，后面就可以直接通过args使用</span></span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure><p>type：把从命令行输入的结果转成设置的类型<br>default：设置参数的默认值<br>action：参数出发的动作<br>help：参数命令的介绍<br>store_ture/store_false：保存相应的布尔值<br>choice：允许的参数值</p><p>dest：如果提供dest，例如dest=”a”，那么可以通过args.a访问该参数<br>store：保存参数，默认<br>store_const：保存一个被定义为参数规格一部分的值（常量），而不是一个来自参数解析而来的值。<br>append：将值保存在一个列表中。<br>append_const：将一个定义在参数规格中的值（常量）保存在一个列表中。<br>count：参数出现的次数<br>version：打印程序版本信息</p><p>2、<code>pathlib.path</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line">p = Path(<span class="string">&quot;xxx&quot;</span>)</span><br><span class="line"><span class="comment"># 常用</span></span><br><span class="line">p.mkdir()<span class="comment">#创建目录</span></span><br><span class="line">p.cwd()<span class="comment">#返回当前目录的路径对象</span></span><br><span class="line">p.iterdir()<span class="comment">#遍历目录的子目录和文件</span></span><br><span class="line">p.is_dir()<span class="comment">#判断是否是目录，返回布尔值</span></span><br><span class="line">p.is_file()<span class="comment">#判断是否是文件，返回布尔值</span></span><br><span class="line">p.exists()<span class="comment">#判断路径是否存在，返回布尔值</span></span><br><span class="line">p.rename()<span class="comment">#重命名目录或文件夹</span></span><br><span class="line"><span class="comment"># 不常用</span></span><br><span class="line">p.<span class="built_in">open</span>()<span class="comment">#通常用open(p,mode)方式</span></span><br><span class="line">p.stat()<span class="comment">#返回目录或文件信息</span></span><br><span class="line">p.home()<span class="comment">#返回当前用户的根目录</span></span><br><span class="line">p.with_name()<span class="comment">#更改最后一级路劲名</span></span><br><span class="line">p.with_suffix()<span class="comment">#更改后缀</span></span><br><span class="line">p.is_absolute()<span class="comment">#是否是绝对路径</span></span><br><span class="line">p.is_reserved()<span class="comment">#是否是预留路径</span></span><br><span class="line">p.resolve()<span class="comment">#返回绝对路径，WindowsPath</span></span><br><span class="line">p.unlink()<span class="comment">#删除目录或文件</span></span><br><span class="line">p.glob()<span class="comment">#条件遍历目录</span></span><br></pre></td></tr></table></figure></p><p>3、pytorch中list、ndarray、tensor之间的转化</p><ul><li>list&lt;-&gt;ndarray<br>list-&gt;ndarray:<code>np.array(list)</code><br>ndarray-&gt;list:<code>ndarray.tolist()</code><br>list和ndarray的访问：<br>只能<code>list[i][j]</code><br><code>ndarray[i][j]</code>和<code>ndarray[i,j]</code>均可</li><li>ndarray&lt;-&gt;tensor<br>ndarray-&gt;tensor:<code>torch.from_numpy(ndarray类型变量)</code>、<code>torch.tensor(ndarray类型变量)</code><br>tensor-&gt;ndarray:<code>tensor类型变量.numpy()</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">at = torch.ones(<span class="number">5</span>)</span><br><span class="line">an = np.ones(<span class="number">5</span>)</span><br><span class="line">bn = at.numpy()  <span class="comment"># tensor-&gt;ndarray</span></span><br><span class="line">bt = torch.from_numpy(an)  <span class="comment"># ndarray-&gt;tensor</span></span><br><span class="line"><span class="built_in">print</span>(at)</span><br><span class="line"><span class="built_in">print</span>(an)</span><br><span class="line"><span class="built_in">print</span>(bn)</span><br><span class="line"><span class="built_in">print</span>(bt)</span><br></pre></td></tr></table></figure>输出：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>注意：转换期间tensor张量和ndarrayu数组底层内存共享，更改一个量会同时更改另一个量，如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">at += <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(at)</span><br><span class="line"><span class="built_in">print</span>(an)</span><br><span class="line"><span class="built_in">print</span>(bn)</span><br><span class="line"><span class="built_in">print</span>(bt)</span><br></pre></td></tr></table></figure>输出：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>])</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">[<span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span>]</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>如果需要接触这种绑定，可以使用ndarray中的<code>.copy()</code>函数：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cn = at.numpy().copy()</span><br><span class="line">ct = torch.from_numpy(bn.copy())</span><br><span class="line">at -= <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(at)</span><br><span class="line"><span class="built_in">print</span>(an)</span><br><span class="line"><span class="built_in">print</span>(bn)</span><br><span class="line"><span class="built_in">print</span>(bt)</span><br><span class="line"><span class="built_in">print</span>(cn)</span><br><span class="line"><span class="built_in">print</span>(ct)</span><br></pre></td></tr></table></figure>输出：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], dtype=torch.float64)</span><br><span class="line">[<span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span> <span class="number">6.</span>]</span><br><span class="line">tensor([<span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>, <span class="number">6.</span>])</span><br></pre></td></tr></table></figure>可以看到使用了<code>.copy()</code>进行转化的<code>cn</code>、<code>ct</code>不受<code>at -= 5</code>的影响值不变。<br>另外，使用<code>torch.tensor()</code>由ndarray生成tensor也不是内存共享的，<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = np.ones(<span class="number">3</span>)</span><br><span class="line">b = torch.tensor(a)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">a += <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br></pre></td></tr></table></figure>输出：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], dtype=torch.float64)</span><br><span class="line">[<span class="number">4.</span> <span class="number">4.</span> <span class="number">4.</span>]</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>], dtype=torch.float64) </span><br></pre></td></tr></table></figure></li><li>list&lt;-&gt;tensor<br>list-&gt;tensor:<code>torch.tensor(list类型变量)</code>、<code>torch.from_numpy(np.array(l))</code>(list-&gt;ndarray-&gt;tensor)<br>tensor-&gt;list:<code>tensor.tolist()</code>、<code>tensor.numpy().tolist()</code>(tensor-&gt;ndarray-&gt;list)</li><li>list字符与数字的转化<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">string_list=[<span class="string">&#x27;1.0&#x27;</span>,<span class="string">&#x27;2.0&#x27;</span>,<span class="string">&#x27;3.0&#x27;</span>]</span><br><span class="line">float_list=<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>,string_list))</span><br><span class="line"><span class="built_in">print</span>(float_list)</span><br></pre></td></tr></table></figure>输出：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习</title>
      <link href="/2022/09/26/study/pytorch/"/>
      <url>/2022/09/26/study/pytorch/</url>
      
        <content type="html"><![CDATA[<h2 id="datasets"><a href="#datasets" class="headerlink" title="datasets:"></a>datasets:</h2><p><strong><code>datasets.ImageFolder()</code></strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataset=torchvision.datasets.ImageFolder(</span><br><span class="line">                       root, transform=<span class="literal">None</span>, </span><br><span class="line">                       target_transform=<span class="literal">None</span>, </span><br><span class="line">                       loader=&lt;function default_loader&gt;, </span><br><span class="line">                       is_valid_file=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><br>参数详解：<br><strong>root</strong>：图片存储的根目录，即各类别文件夹所在目录的上一级目录。<br><strong>transform</strong>：对图片进行预处理的操作（函数），原始图片作为输入，返回一个转换后的图片。<br>target_transform：对图片类别进行预处理的操作，输入为target，输出对其的转换。如果不传该参数，即对target不做任何转换，返回的顺序索引0,1,2…<br>loader：表示数据集加载方式，通常默认加载方式即可。<br>is_valid_file：获取图像文件的路径并检查该文件是否为有效文件的函数(用于检查损坏文件)</p><h2 id="dataload"><a href="#dataload" class="headerlink" title="dataload:"></a>dataload:</h2><p><strong>1、<code>torch.utils.data.DataLoader</code></strong>：对数据进行batch划分。它是一个数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。在训练模型时使用到此函数，用来把训练数据分成多个小组，此函数每次抛出一组数据，直至把所有的数据都抛出，就是做一个数据的初始化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data_loader_train = torch.utils.data.DataLoader(</span><br><span class="line">        dataset=dataset_train, </span><br><span class="line">        batch_size=args.batch_size,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        sampler=sampler_train,</span><br><span class="line">        batch_sampler=<span class="literal">False</span>,</span><br><span class="line">        num_workers=args.num_workers,</span><br><span class="line">        pin_memory=args.pin_mem,</span><br><span class="line">        drop_last=<span class="literal">True</span>,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><br>参数详解：<br><strong>dataset</strong>：dataset数据类型，输入的原始数据。<br><strong>batch_size</strong>：int数据类型，批训练数据量的大小，默认为1。PyTorch训练模型时调用数据不是一行一行进行的，而是一捆一捆进行的。batch_size就是定义每次给神经网络多少行数据，如果设置成1，那就是一行一行进行。每次是随机读取大小为batch_size。如果dataset中的数据个数不是batch_size的整数倍，这最后一次把剩余的数据全部输出。若想把剩下的不足batch size个的数据丢弃，则将drop_last设置为True，会将多出来不足一个batch的数据丢弃。<br><strong>sampler</strong>：Sampler数据类型，采样，默认设置为None。根据定义的策略从数据集中采样输入。如果定义采样规则，则洗牌（shuffle）设置必须为False。<br><strong>shuffle</strong>：bool数据类型，默认为False，表示在每次迭代训练时是否将数据打乱。将输入数据的顺序打乱，是为了使数据更有独立性，但如果数据是有序列特征的，就不要设置成True了。<br><strong>drop_last</strong>：bool数据类型，丢弃最后数据，默认为False。设置了batch_size 的数目后，最后一批数据未必是设置的数目，有可能会小些，这时你是否需要丢弃这批数据。<br>num_workers：int数据类型，工作者数量，默认是0。使用多少个子进程来导入数据。设置为0，就是使用主进程来导入数据。注意：这个数字必须是大于等于0的，负数估计会出错。<br>pin_memory：bool数据类型，内存寄存，默认为False。在数据返回前，是否将数据复制到CUDA内存中。<br>batch_sampler：Sampler数据类型，批量采样，默认设置为None。但每次返回的是一批数据的索引（注意：不是数据）。其和batch_size、shuffle 、sampler and drop_last参数是不兼容的。<br>timeout：numeric数据类型，超时，默认为0。是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错，所以，数值必须大于等于0。<br>collate_fn：callable数据类型，将一小段数据合并成数据列表，默认设置是False。如果设置成True，系统会在返回前会将张量数据（Tensors）复制到CUDA内存中。（没怎么用过）<br>worker_init_fn：callable数据类型，子进程导入模式，默认为None。在数据导入前和步长结束后，根据工作子进程的ID逐个按顺序导入数据。<br><strong>2、<code>torch.utils.data.distributed.DistributedSampler()</code></strong>：分布式数据，用于多卡训练，注意<code>sampler.set_epoch(epoch)</code>的使用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sampler_train = torch.utils.data.DistributedSampler(</span><br><span class="line">   dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br><strong>dataset</strong>：输入的原始数据<br>num_replicas：参与分布式训练的进程数，默认情况下将自己检索这个参数。<br>rank：当前进程的编号，默认情况下将自己检索这个参数。<br>shuffle：是否打乱数据集，默认为True。<br>seed：当shuffle=True时，用于random的随机数种子。这个参数在所有分布式进程中必须保持一致，默认为False。<br>具体参见：<a href="https://blog.csdn.net/weixin_45738220/article/details/112151455">链接1</a>、<a href="https://blog.csdn.net/searobbers_duck/article/details/115299691">链接2</a></p><h2 id="transforms"><a href="#transforms" class="headerlink" title="transforms:"></a>transforms:</h2><p>1、<strong><code>transforms.Compose()</code></strong><br><code>transforms.Compose()</code>用于整合一系列的图像变换函数，将图片按照<code>Compose()</code>中的顺序依次处理。<code>torch.nn.Sequential()</code>与<code>transforms.Compose()</code>起到相同的功能。<code>torch.nn.Sequential()</code>和<code>torch.jit.script()</code>结合来导出模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;Compose&#x27;&#x27;&#x27;</span></span><br><span class="line">transform1 = transforms.Compose([</span><br><span class="line">transforms.CenterCrop(<span class="number">10</span>),</span><br><span class="line">transforms.Normalize((<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;Sequential&#x27;&#x27;&#x27;</span></span><br><span class="line">transform2 = torch.nn.Sequential(</span><br><span class="line">transforms.CenterCrop(<span class="number">10</span>),</span><br><span class="line">transforms.Normalize((<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)),</span><br><span class="line">)</span><br><span class="line">scripted_transforms = torch.jit.script(transforms)</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><code>torch.nn.Sequential()</code>和<code>transforms.Compose()</code>中都能加入一系列的图像变换函数，相关transforms中数据增强、图像变换的方法可参见<a href="https://blog.csdn.net/Miao_sin/article/details/122474968">链接</a></p><p>2、内部具体函数<br><code>transforms.RandomResizedCrop()</code><br>将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为制定的大小；（即先随机采集，然后对裁剪得到的图像缩放为同一大小）<br><strong>参数解释：</strong><br>size：该参数用于Resize功能，指定最终得到的图片大小。如果size是一个int值，如H，则最终图片大小为HxH，如果size是一个二元组，如（H，W），则最终图片大小为HxW。size参数跟crop功能完全没关系。<br>scale：该参数用于Crop功能，指定裁剪区域的面积占原图像的面积的比例范围，是一个二元组，如（scale_lower, scale_upper），我们会在[scale_lower, scale_upper]这个区间中随机采样一个值scale_a，则裁剪区域的面积S_crop=image_height <em> image_width </em> scale_a。 即scale_a表示从原图片中裁剪多大的一部分区域。而scale参数是scale_a的取值范围。<br>ratio：该参数用于Crop功能，指定裁剪区域的宽高比范围，是一个二元组，如（ratio_lower,ratio_upper），我们会在[scale_lower, scale_upper]这个区间中随机采样一个值ratio_a，则裁剪区域的宽/裁剪区域的高 = ratio_a。即宽高比。根据scale我们可以确定裁剪区域的面积为S_crop，现在我们可以根据宽高比，求得裁剪区域的高 = sqrt(S_crop / ratio_a)，裁剪区域的宽 = sqrt(S_crop * ratio_a)。sqrt是平方根函数。<br>interpolation：该参数用于Resize功能，指缩小或者扩大图像的时候，使用什么样的插值方法。<code>NEAREST</code>、<code>BILINEAR</code>、<code>BICUBIC</code>等</p><p><code>transforms.RandomHorizontalFlip()</code><br>以给定的概率随机水平旋转给定的PIL的图像，默认为0.5</p><p><code>transforms.ToTensor()</code><br>将numpy的ndarray或PIL.Image读的图片转换成形状为(C,H,W)的Tensor格式，且/255归一化到[0,1]之间</p><p><code>transforms.Normalize()</code><br>用平均值和标准偏差归一化张量图像。给定mean和std,对于n通道，此变换将标准化输入的每个通道，<code>input[channel] = (input[channel] - mean[channel]) / std[channel]</code></p><p>具体参见：<a href="https://blog.csdn.net/qq_36523492/article/details/107357532">链接1</a>、<a href="https://blog.csdn.net/yanzhiwen2/article/details/123870111">链接2</a></p><h2 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(number) </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">设置CPU生成随机数的种子，方便下次复现实验结果。为CPU设置种子用于生成随机数，以使得结果是确定的。</span></span><br><span class="line"><span class="string">当你设置一个随机种子时，接下来的随机算法生成数根据当前的随机种子按照一定规律生成。随机种子作用域是在设置时到下一次设置时。</span></span><br><span class="line"><span class="string">要想重复实验结果，设置同样随机种子即可。number不变，每次运行时随机数就不变</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">torch.cuda.manual_seed(number)  <span class="comment"># 为特定GPU设置种子，生成随机数：</span></span><br><span class="line">torch.cuda.manual_seed_all(number)  <span class="comment"># 如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git使用</title>
      <link href="/2022/09/20/teach/git/"/>
      <url>/2022/09/20/teach/git/</url>
      
        <content type="html"><![CDATA[<h1 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h1><p><a href="https://blog.csdn.net/mukes/article/details/115693833">参考链接</a></p><h1 id="电脑连接github"><a href="#电脑连接github" class="headerlink" title="电脑连接github"></a>电脑连接github</h1><p><strong>1、个人电脑生成密钥和公钥</strong><br>打开git bash命令行窗口，输入命令：<code>git-keygen -t rsa</code>，指定RSA算法来生成秘钥，执行命令后敲击三次回车，之后会生成两个文件<code>id_rsa</code>和<code>id_rsa_pub</code>,默认保存在 <code>C:\Users\XXX\.ssh</code>目录下.<br><strong>2、将公钥绑定到github上</strong><br>打开github-&gt;Settings-&gt;SSH and GPG keys，添加New SSH key，将id_rsa_pub里的内容复制过来。<br><strong>3、验证</strong><br>打开git bash命令行窗口，输入命令：<code>ssh -T git@github.com</code>，如果出现：<code>Hi XXX! You&#39;ve successfully authenticated, but GitHub does not provide she access.</code>则表示连接成功。<br><strong>4、电脑连接github账户</strong><br>完成上面操作后可以实现从github上下载项目，但是<code>git commit</code>时会出现错误，应该还要打开git bash命令行窗口，输入命令：<code>git config --global user.email &quot;you@example.com&quot;</code>和<code>git config --global user.name &quot;Your Name&quot;</code>，执行完后即可实现项目上传。</p><h1 id="github使用"><a href="#github使用" class="headerlink" title="github使用"></a>github使用</h1><h2 id="有本地仓库"><a href="#有本地仓库" class="headerlink" title="有本地仓库"></a>有本地仓库</h2><p>在github上新建仓库，使用push操作同步到github上</p><h3 id="push操作"><a href="#push操作" class="headerlink" title="push操作"></a>push操作</h3><p>本地代码上传同步远程仓库<br><strong>初始push</strong><br>git init<br>git branch -M main<br>git remote add origin git@github.com:username/reponame.git<br>git add .<br>git commit -m “first commit”<br>git push -u origin main</p><p><strong>之后push</strong><br>git add xxx<br>git commit -m “first commit”<br>git push -u origin main</p><h3 id="pull操作"><a href="#pull操作" class="headerlink" title="pull操作"></a>pull操作</h3><p>远程仓库代码下载同步到本地<br>git pull origin main</p><p>有时候需要（git clean -d -fx）<br><strong>注意</strong><br>若在github中直接删除或增加文件，则需要：<br>git pull —rebase origin master<br>先将git库中的变化同步到本地，再进行push</p><h2 id="无本地仓库"><a href="#无本地仓库" class="headerlink" title="无本地仓库"></a>无本地仓库</h2><p>直接从github上克隆下来即可<br>在需要存放仓库的文件夹上一级目录下打开git bash，输入命令git clone git@github.com:username/reponame.git<br>之后即和之前push、pull操作一致</p><p><strong>注意：记得每一次在本地修改文件时记得一定要先pull再修改，改完后再push，防止之后有问题</strong></p><h1 id="PowerShell使用"><a href="#PowerShell使用" class="headerlink" title="PowerShell使用"></a>PowerShell使用</h1><p>在PowerShell和vscode终端想使用git命令，最开始会报错“无法加载文件,因为在此系统上禁止运行脚本。”，此时需要以管理员身份运行Windows PowerShell，输入命令：<code>set-ExecutionPolicy RemoteSigned</code>，最后使用<code>get-executionpolicy</code>来查看是否更改成功，显示RomoteSigned则表示更改成功，之后则可以再vscode、Pycharm终端中直接使用PowerShell命令行窗口。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实验室生涯开启篇</title>
      <link href="/2022/09/15/life/study_anomaly/"/>
      <url>/2022/09/15/life/study_anomaly/</url>
      
        <content type="html"><![CDATA[<p>正式开始了实验室生涯，尽可能有时间就记录一下！</p><h2 id="day-1"><a href="#day-1" class="headerlink" title="day 1"></a>day 1</h2><p>下午进组，完成单张图片对比找不同实现mask策略，效果很不错</p><h2 id="day-2"><a href="#day-2" class="headerlink" title="day 2"></a>day 2</h2><p>完成与多张图片对比得到不同，发现当初步找出的不同块过多时，得到的重建图像会出错，模糊不清，减少用于对比度正常样本后，效果变好，要进一步调整参数</p><h2 id="day-3"><a href="#day-3" class="headerlink" title="day 3"></a>day 3</h2><p>找像素点方法出错，对于有旋转等变换的样本出错几率大，修改初检方法</p><h2 id="day-4"><a href="#day-4" class="headerlink" title="day 4"></a>day 4</h2><p>进度很小，修改初检方法都只能单独针对某一种或者少数几种类别样本完成初检<br>直接用数据集中的ground_truth进行mask指导，发现对于小的异常更能检测到，但对于大的异常由于mask较多，而且mask块过大，直接使用MAE原模型用于重建会出现过于模糊甚至重建出错的问题。patch块过大，重建之后纹理不清晰<br>使用MAE微调重新构建参数模型，但是自己的电脑显存不够。</p><h2 id="day-5"><a href="#day-5" class="headerlink" title="day 5"></a>day 5</h2><p>mask策略遇到问题，先实现了异常定位msgms， 得到的结果比较准确</p><h2 id="day-6"><a href="#day-6" class="headerlink" title="day 6"></a>day 6</h2><p>继续学习MAE源码，用MVTec完成模型的微调。<br>1、MVTec数据集的均值和方差计算<br>2、修改forward_loss</p><p>使用vit_base模型进行微调，未超出显存，可以使用<br>遇到警告：<br>UserWarning: Argument ‘interpolation’ of type int is deprecated since 0.13 and will be removed in 0.15</p><p>timm的helpers.py中由<code>from torch._six import container_abcs</code>-&gt;<code>import collections.abc as container_abcs</code></p><p>微调之后效果反而更差，准备直接预训练</p><h2 id="day-7"><a href="#day-7" class="headerlink" title="day 7"></a>day 7</h2><p>用3090服务器跑代码时发现算力与cuda版本不匹配，重新更新环境。<br>使用自己的电脑跑模型，迭代50个epoch后L2损失为0.16，还需要继续迭代。</p><h2 id="day-8"><a href="#day-8" class="headerlink" title="day 8"></a>day 8</h2><p>继续跑代码，在Autodl服务器上跑代码：<br>预训练：<br>迭代500次，loss为0.3061060717812291<br>微调：<br>无论迭代多少次，可视化效果极差</p><h2 id="day-9"><a href="#day-9" class="headerlink" title="day 9"></a>day 9</h2><p><strong>22.9.28</strong><br>继续读MAE源代码：找到了下载模型的链接如下：</p><blockquote><p><code>https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth</code><br><code>https://dl.fbaipublicfiles.com/mae/pretrain/mae_pretrain_vit_base.pth</code><br><code>https://dl.fbaipublicfiles.com/mae/finetune/mae_finetuned_vit_base.pth</code></p></blockquote><p>使用<code>visualize</code>模型效果特别好，但使用<code>pretrain</code>和<code>finetuned</code>模型效果很差<br>读源码时发现，有的参数必须要用终端运行程序才有效，所以：</p><blockquote><p><code>python main_finetune.py --mixup 0.8 --cutmix 1.0 --pin_mem --blr 5e-4 --layer_decay 0.65 --dist_eval</code><br><code>python main_finetune.py --eval --resume G:/MAE/output_dir_fine1/checkpoint-6.pth</code><br><code>python main_pretrain.py --norm_pix_loss --blr 1.5e-4</code></p></blockquote><p>预训练迭代800次，loss为：0.05635738572864621，似乎还没收敛，但可视化效果已经开始变好。<br>python submitit_pretrain.py —norm_pix_loss —blr 5e-2</p><h2 id="day-10"><a href="#day-10" class="headerlink" title="day 10"></a>day 10</h2><p><strong>22.10.3</strong><br>MVTec数据集太卷了，准备自己制造数据集，完成了insulator数据集的制造<br>问题：找不到什么样的叫做有异常。</p><h2 id="day-11"><a href="#day-11" class="headerlink" title="day 11"></a>day 11</h2><p><strong>22.10.4</strong><br>在实验室服务器上安装cuda、cudnn、anoconda等，上传数据集和代码，开始跑代码。<br>遇到报错：<br>MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.<br>解决：将<code>matplotlib</code>退回到3.5.2版本</p><p>服务器连接本地使用jupyter完成，之后继续学习指定卡和多卡代码运行。</p><h2 id="day-12"><a href="#day-12" class="headerlink" title="day 12"></a>day 12</h2><p><strong>22.10.5</strong><br>在服务器上继续预训练模型<br>将所有数据集进行可视化并裁剪，制作需要的数据集<br>完成可视化以及裁剪操作，数据集制作完成<br>但是找不到缺陷，不了解什么情况是异常！！！</p><h2 id="day-13"><a href="#day-13" class="headerlink" title="day 13"></a>day 13</h2><p><strong>22.10.7</strong><br>高铁接触网存在缺陷的地方：<br>1、绝缘子：表面掉漆、缺损、脏污、有异物<br>2、防风线、吊弦、刚性吊弦：断裂、弯曲、破损等<br>3、开合销（多种）：缺失、安装不到位<br>4、紧固件：缺失、潜在缺失（安装不到位）</p><p>吊弦——霍夫变换得到异常候选区域(Multialgorithm Fusion Image Processing for High Speed Railway Dropper Failure–Defect Detection)<br>可重点参考：A Generic Anomaly Detection of Catenary Support Components Based on Generative Adversarial Networks</p><p>SPs：split pins——开口销<br>CSDs：catenary support devices——接触网支撑装置</p><h2 id="day-14"><a href="#day-14" class="headerlink" title="day 14"></a>day 14</h2><p><strong>22.10.8</strong><br>图片的size由224-&gt;512，训练量大大增加，训练800epoch，loss还降不下去，但得到的效果比224清晰</p><h2 id="day-15"><a href="#day-15" class="headerlink" title="day 15"></a>day 15</h2><p><strong>22.10.10</strong><br>将样本分类，找出能用于训练的正常数据集</p><h2 id="day-16"><a href="#day-16" class="headerlink" title="day 16"></a>day 16</h2><p><strong>22.10.11</strong><br>继续使用MVTec数据集进行input-size为512的预训练，发现效果显著提高，只是训练时间会大大增加<br>TITAN XP训练：<code>python main_pretrain.py --norm_pix_loss --blr 0.15</code>，会出现学习率过大导致<code>Loss is nan, stopping training</code> ，使用的batch-size=6*8=48</p><p>3090训练：<code>python main_pretrain.py --norm_pix_loss --blr 5e-3</code>，正常训练，使用的batch-size=32*1=32，迭代2000次，loss还没降下去。</p><h2 id="day-17"><a href="#day-17" class="headerlink" title="day 17"></a>day 17</h2><p><strong>22.10.12</strong><br>调整学习率继续进行训练<br>继续完成数据集的制作</p><h2 id="day-18"><a href="#day-18" class="headerlink" title="day 18"></a>day 18</h2><p><strong>22.10.13</strong><br>数据集制作基本完成，发现使用input_size为224的模型在新数据集上可行，所以之后在不改变input_size情况下直接微调得到训练模型</p><h2 id="day-19"><a href="#day-19" class="headerlink" title="day 19"></a>day 19</h2><p><strong>22.11.9</strong><br>近段时间都在调整数据集，挑选出正常样本。<br>由于没有服务器可用，重新开始读论文，寻找初检的方法，先大致确定使用显著性检测(Saliency Detection)</p><h2 id="day-20"><a href="#day-20" class="headerlink" title="day 20"></a>day 20</h2><p><strong>22.11.11</strong><br>完成正常数据集的裁剪，挑选之后即可用于训练<br>开始挑选可用于训练的正常样本。</p><h2 id="day-21"><a href="#day-21" class="headerlink" title="day 21"></a>day 21</h2><p><strong>22.11.14</strong><br>挑选正常样本，开始进行预训练。<br>TITAN XP:<br>prebase-32(500):python main_pretrain.py —norm_pix_loss —blr 1.5e-2  出现Loss is nan, stopping training，所以降低学习率，改为：<br>prebase-32(500-1):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，有些部分重建很差，加大迭代次数，使用2000次迭代：<br>prebase-32(500):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，对于背景部分的重建依旧很差。</p><p>prebase-64(500-3):python main_pretrain.py —norm_pix_loss —blr 1e-2  出现Loss is nan, stopping training，所以降低学习率，改为：<br>prebase-64(500-2):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，有些部分重建很差，加大迭代次数，2000次迭代：<br>prebase-64(500-3):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，对于背景白色部分的重建依旧很差。</p><p>prelarge-32(500):python main_pretrain.py —norm_pix_loss —blr 1.5e-2   出现Loss is nan, stopping training，所以降低学习率，改为：<br>prelarge-32(800):python main_pretrain.py —norm_pix_loss —blr 5e-3     运行成功：用于推理，有些部分重建很差，暂时放弃large模型。</p><h2 id="day-22"><a href="#day-22" class="headerlink" title="day 22"></a>day 22</h2><p><strong>22.11.15</strong><br>运行结果如上。<br>继续调试，推理过程中发现，背景部分重建效果极差，所以尝试将白色背景换成黑色，且保持原尺寸比例，重新进行训练<br>prebase-32(800):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，对于背景部分的重建依旧很差。</p><p>prebase-32(2000):python main_pretrain.py —norm_pix_loss —blr 5e-3  运行成功：用于推理，对于背景部分的重建依旧很差。</p><p>prebase-32(800-1):python main_pretrain.py —norm_pix_loss —blr 8e-3  运行成功：用于推理，对于背景部分的重建依旧很差。</p><h2 id="day-23"><a href="#day-23" class="headerlink" title="day 23"></a>day 23</h2><p><strong>22.11.16</strong><br>预训练出来之后重建效果很差，重新阅读源码，理解含义。</p><h2 id="day-24"><a href="#day-24" class="headerlink" title="day 24"></a>day 24</h2><p><strong>22.11.20</strong><br>在3090上在运行白色背景的样本进行预训练。<br>运行4个base、2个large，同样背景重建很差，但对于绝缘子而言重建较好，只要异常处被mask，则重建出来即是正常样本</p><h2 id="day-25"><a href="#day-25" class="headerlink" title="day 25"></a>day 25</h2><p><strong>22.11.22</strong><br>修改训练过程中数据集的均值和方差，在3090上重新进行训练<br>重建效果依旧不理想，而且loss收敛更慢。</p><p>命名规则：32—b—5—bb -&gt; batch size=32 — model=base — epoch=500 — 数据集为black_b<br>32b5bb:python main_pretrain.py —norm_pix_loss —blr 5e-3<br>32b5bs:python main_pretrain.py —norm_pix_loss —blr 5e-3<br>32b5ws:python main_pretrain.py —norm_pix_loss —blr 5e-3<br>32b5wb:python main_pretrain.py —norm_pix_loss —blr 5e-3</p><p>64b20bs:python main_pretrain.py —norm_pix_loss —blr 5e-3  出现Loss is nan, stopping training<br>64b20ws:python main_pretrain.py —norm_pix_loss —blr 5e-3<br>32b20ws:python main_pretrain.py —norm_pix_loss —blr 5e-3<br>32b20bs:python main_pretrain.py —norm_pix_loss —blr 5e-3</p><h2 id="day-26"><a href="#day-26" class="headerlink" title="day 26"></a>day 26</h2><p><strong>22.11.23</strong><br>重新调试代码，寻找重建颜色错误的原因</p><h2 id="day-27"><a href="#day-27" class="headerlink" title="day 27"></a>day 27</h2><p><strong>22.11.24</strong><br>单步调试，读懂代码，发现输入图像无需padding成$224 \times 224$，代码数据增强部分有操作<br>重新计算未padding样本的均值和方差参与计算<br>16b20：样本均值方差  Training time 14:57:35<br>32b20：样本均值方差  Training time 10:40:26<br>16b20-1：Imagenet均值方差  Training time 14:31:22<br>32b20-1：Imagenet均值方差  Training time 10:45:05<br>效果都比较差</p><h2 id="day-28"><a href="#day-28" class="headerlink" title="day 28"></a>day 28</h2><p><strong>22.11.25</strong><br>不用padding时，重建时样本没有$224 \times 224$，若用padding的话，背景重建会出错，所以还是使用带padding的样本进行训练，并使用各自的均值方差<br>64b5b:$160 \times 64$ 黑色背景<br>64b5b-1:$176 \times 64$ 黑色背景<br>64b5w-1:$176 \times 64$ 白色背景<br>32b5w:$160 \times 64$ 白色背景<br>效果依然较差<br>使用Imagenet均值方差再试试，并调小学习率<br>32b20b:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —norm_pix_loss —blr 1.5e-4  Training time 10:13:49<br>32b20w:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —norm_pix_loss —blr 1.5e-4  Training time 10:34:15<br>32b20b-1:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —norm_pix_loss —blr 5e-4  Training time 10:39:15<br>32b20w-1:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —norm_pix_loss —blr 5e-4  Training time 10:44:33<br>效果不好<br>在训练时计算loss时不做归一化：<br>32b20b-2:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-4  Training time 14:01:42<br>32b20w-2:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-4  Training time 13:59:18<br>效果很好</p><h2 id="day-29"><a href="#day-29" class="headerlink" title="day 29"></a>day 29</h2><p><strong>22.11.26</strong><br>在训练时计算loss时不做归一化得到了很好的效果。继续探索影响因素<br>32b10w2:不改变原始样本比例填充，白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 4:59:20<br>32b10w2-1:不改变原始样本比例填充，白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 5:10:51<br>32b10b2:不改变原始样本比例填充，黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 5:15:37<br>32b10b2-1:不改变原始样本比例填充，黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 5:13:13<br>32b10w1:$176 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:58:29<br>32b10b1:$176 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:59:24<br>TITAN<br>16b10w:$160 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10b:$160 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10w1:$176 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10b1:$176 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3</p><p>报错：NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.<br>3090<br>32b10w1-1:$176 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10b1-1:$176 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10w:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10b:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10w-1:$160 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3<br>32b10b-1:$160 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3</p><p>综合一下，影响因素有样本内容大小、背景颜色、均值方差<br>32b10w2:不改变原始样本比例填充，白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 4:59:20<br>32b10b2:不改变原始样本比例填充，黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 5:15:37<br>32b10w2-1:不改变原始样本比例填充，白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 5:10:51<br>32b10b2-1:不改变原始样本比例填充，黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 5:13:13<br>32b10w1:$176 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:58:29<br>32b10b1:$176 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:59:24<br>32b10w1-1:$176 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 4:59:07<br>32b10b1-1:$176 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 5:10:20<br>32b10w:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 5:12:49<br>32b10b:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 5:17:03<br>32b10w-1:$160 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 6:58:47<br>32b10b-1:$160 \times 64$ 黑色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 6:57:04</p><h2 id="day-30"><a href="#day-30" class="headerlink" title="day 30"></a>day 30</h2><p><strong>22.11.27</strong><br>尝试一下input size=256，便于之后多尺度mask<br>16b10w1_256:$176 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 8:34:17<br>16b10w1-1_256:$176 \times 64$ 白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 8:28:51<br>16b10w2_256:不改变原始样本比例填充，白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 7:58:46<br>16b10w2-1_256:不改变原始样本比例填充，白色背景 样本数据集均值方差 python main_pretrain.py —blr 5e-3  Training time 8:29:40<br>32_MVTec_256:Imagenet均值方差 input size=256 python main_pretrain.py —blr 5e-3  Training time 9:45:46<br>MVTec_512:Imagenet均值方差 input size=512 python main_pretrain.py —blr 5e-3 Training time 2 days, 4:58:58</p><h2 id="day-31"><a href="#day-31" class="headerlink" title="day 31"></a>day 31</h2><p><strong>22.11.28</strong><br>分析效果好坏，所有效果都是好的<br>对于Imagenet均值方差，write-1、write-2、black-1效果更好，其中write-1效果最好<br>对于样本数据集均值方差，重建效果都差不多，write-2效果更好，但比Imagenet均值方差效果差<br>Imagenet效果更好，所以之后实验选择使用Imagenet均值方差<br>大多数情况下白色背景比黑色背景效果要好，但有的样本在黑色背景下重建效果更好<br>32b10b_256:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:27:09<br>32b10w_256:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 6:48:06<br>32b10b_288:$160 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 8:10:41<br>32b10w_288:$160 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 8:16:07<br>32b10b1_288:$176 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 10:33:22<br>32b10w1_288:$176 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 10:01:13<br>32b10w2_288:不改变原始样本比例填充 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3  Training time 9:06:56</p><h2 id="day-32"><a href="#day-32" class="headerlink" title="day 32"></a>day 32</h2><p><strong>22.11.29</strong><br>继续把还没有跑完的模型跑完<br>32b10b1_256:$176 \times 64$ 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10w1_256:$176 \times 64$ 白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10b2_256:不改变原始样本比例填充，黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10w2_256:不改变原始样本比例填充，白色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3<br>32b10b2_288:不改变原始样本比例填充 黑色背景 Imagenet均值方差 python main_pretrain.py —blr 5e-3</p><p>综合已经训练完成的模型：<br>imagenet224:（已完成所有）<br>32b10w: $160 \times 64$  白色背景 Imagenet均值方差 Training time 5:12:49<br>32b10b: $160 \times 64$  黑色背景 Imagenet均值方差 Training time 5:17:03<br>32b10w1:$176 \times 64$  白色背景 Imagenet均值方差 Training time 6:58:29<br>32b10b1:$176 \times 64$  黑色背景 Imagenet均值方差 Training time 6:59:24<br>32b10w2:不改变原始样本比例 白色背景 Imagenet均值方差 Training time 4:59:20<br>32b10b2:不改变原始样本比例 黑色背景 Imagenet均值方差 Training time 5:15:37<br>yangben224:（已完成所有）<br>32b10w-1: $160 \times 64$  白色背景 样本数据集均值方差 Training time 6:58:47<br>32b10b-1: $160 \times 64$  黑色背景 样本数据集均值方差 Training time 6:57:04<br>32b10w1-1:$176 \times 64$  白色背景 样本数据集均值方差 Training time 4:59:07<br>32b10b1-1:$176 \times 64$  黑色背景 样本数据集均值方差 Training time 5:10:20<br>32b10w2-1:不改变原始样本比例 白色背景 样本数据集均值方差 Training time 5:10:51<br>32b10b2-1:不改变原始样本比例 黑色背景 样本数据集均值方差 Training time 5:13:13<br>imagenet256:（差一个32b10w2_256）<br>32b10w_256: $160 \times 64$  白色背景 Imagenet均值方差 Training time 6:48:06<br>32b10b_256: $160 \times 64$  黑色背景 Imagenet均值方差 Training time 6:27:09<br>32b10w1_256:$176 \times 64$  白色背景 Imagenet均值方差 Training time 6:41:08<br>32b10b1_256:$176 \times 64$  黑色背景 Imagenet均值方差 Training time 6:39:57<br>32b10w2_256:不改变原始样本比例 白色背景 Imagenet均值方差 Training time 6:21:19<br>32b10b2_256:不改变原始样本比例 黑色背景 Imagenet均值方差 Training time 6:44:29</p><p>16b10w1_256: $176 \times 64$ 白色背景 Imagenet均值方差 Training time 8:34:17<br>16b10w2_256:不改变原始样本比例 白色背景 Imagenet均值方差 Training time 7:58:46<br>yangben256:（暂时不需要）<br>16b10w1-1_256: $176 \times 64$ 白色背景 样本数据集均值方差 Training time 8:28:51<br>16b10w2-1_256:不改变原始样本比例 白色背景 样本数据集均值方差 Training time 8:29:40<br>imagenet288:<br>32b10w_288: $160 \times 64$  白色背景 Imagenet均值方差 Training time 8:16:07<br>32b10b_288: $160 \times 64$  黑色背景 Imagenet均值方差 Training time 8:10:41<br>32b10w1_288:$176 \times 64$  白色背景 Imagenet均值方差 Training time 10:01:13<br>32b10b1_288:$176 \times 64$  黑色背景 Imagenet均值方差 Training time 10:33:22<br>32b10w2_288:不改变原始样本比例 白色背景 Imagenet均值方差 Training time 9:06:56<br>32b10b2_288:不改变原始样本比例 黑色背景 Imagenet均值方差 Training time 9:01:53</p><h2 id="day-33"><a href="#day-33" class="headerlink" title="day 33"></a>day 33</h2><p><strong>22.11.30</strong><br>推理过程很慢，需要优化.<br>尝试使用ssim和gmsd进行异常定位，发现边缘处存在误检，破损和脏污检测效果不好，需继续找更好的方法。</p><h2 id="day-34"><a href="#day-34" class="headerlink" title="day 34"></a>day 34</h2><p><strong>22.11.31</strong><br>完成热力图的生成，对于大脏污的检测有所改进，但对于破损效果不行。<br>经过实验发现使用write-1和imagenet256效果更好，之后只考虑对此进行实验。</p><h2 id="day-35"><a href="#day-35" class="headerlink" title="day 35"></a>day 35</h2><p><strong>22.12.3</strong><br>32b20w1_288:Training time 14:34:41<br>32b20w1_256:Training time 11:33:41</p><h2 id="day-36"><a href="#day-36" class="headerlink" title="day 36"></a>day 36</h2><p><strong>22.12.4</strong><br>制作test数据集，微调train数据集。</p><h2 id="day-37"><a href="#day-37" class="headerlink" title="day 37"></a>day 37</h2><p><strong>22.12.5</strong><br>完成所有数据集的制作，开始进行实验，采用：$176 \times 64$  白色背景 Imagenet均值方差。</p><h2 id="day-38"><a href="#day-38" class="headerlink" title="day 38"></a>day 38</h2><p><strong>22.12.6</strong><br>继续训练large模型，并将迭代次数增加到2000次。</p><h2 id="day-39"><a href="#day-39" class="headerlink" title="day 39"></a>day 39</h2><p><strong>22.12.7</strong><br>将测试集进行推理可视化，发现异常过大会导致重建效果差、异常过小异常定位失败，继续调试GMSD，并进行异常检测和定位的评价指标计算。</p><h2 id="day-40"><a href="#day-40" class="headerlink" title="day 40"></a>day 40</h2><p><strong>22.12.8</strong><br>继续读论文，找到更好的异常定位方法，计算异常检测和异常定位的ROCAUC，需要异常图像的GT<br>暂时只做异常检测，异常定位只做可视化，不做性能评估</p><h2 id="day-41-46"><a href="#day-41-46" class="headerlink" title="day 41-46"></a>day 41-46</h2><p><strong>22.12.9-22.12.14</strong><br>2000次迭代实验，由于服务器出现了问题，实验跑一半重新跑。<br>b20w1_224:python main_pretrain.py —blr 5e-3  Training time 13:50:53<br>b20w1_256:python main_pretrain.py —blr 5e-3  Training time 19:53:49<br>b20w1_288:python main_pretrain.py —blr 5e-3  Training time 1 day, 1:49:44</p><p>l20w1_224:python main_pretrain.py —blr 1e-3  Training time 1 day, 7:06:46<br>l20w1_256:python main_pretrain.py —blr 1e-3  Training time 1 day, 11:12:55<br>l20w1_288:python main_pretrain.py —blr 1e-3  Training time 21:09:09</p><p>b20b1_224:python main_pretrain.py —blr 5e-3  Training time 15:01:15<br>b20b1_256:python main_pretrain.py —blr 5e-3  Training time 19:19:19<br>b20b1_288:python main_pretrain.py —blr 5e-3  Training time 19:33:09</p><p>l20b1_224:python main_pretrain.py —blr 1e-3  Training time 14:37:35<br>l20b1_256:python main_pretrain.py —blr 1e-3  Training time 17:57:53<br>l20b1_288:python main_pretrain.py —blr 1e-3  Training time 1 day, 2:29:33</p><p>b20b1_224-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 15:11:01<br>b20b1_256-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 19:18:43<br>b20b1_288-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 19:24:40</p><p>l20w1_224-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 1 day, 3:45:02<br>l20w1_256-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 1 day, 11:13:57<br>l20w1_288-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 21:00:13</p><p>b20w1_224-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 15:18:03<br>b20w1_256-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 19:44:19<br>b20w1_288-1:样本均值方差  python main_pretrain.py —blr 5e-3  Training time 19:38:44</p><p>l20b1_224-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 1 day, 3:45:42<br>l20b1_256-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 1 day, 1:04:46<br>l20b1_288-1:样本均值方差  python main_pretrain.py —blr 1e-3  Training time 21:00:59</p><h2 id="day-47"><a href="#day-47" class="headerlink" title="day 47"></a>day 47</h2><p><strong>23.2.27</strong><br>完成abstract和introduction</p><h2 id="day-48-51"><a href="#day-48-51" class="headerlink" title="day 48-51"></a>day 48-51</h2><p><strong>23.2.28-23.3.3</strong><br>完成数据集分析，完成datset模块的修改</p><h2 id="day-52"><a href="#day-52" class="headerlink" title="day 52"></a>day 52</h2><p><strong>23.3.6</strong><br>修改检测算法，由GMSD改为SSIM</p><h2 id="day-53"><a href="#day-53" class="headerlink" title="day 53"></a>day 53</h2><p><strong>23.3.7</strong><br>继续修改SSIM，主要解决大缺陷下误检过多的问题<br>训练未进行分类的数据集：<br>fbno-&gt;未分类<br>insfb-&gt;分类</p><h2 id="day-54"><a href="#day-54" class="headerlink" title="day 54"></a>day 54</h2><p><strong>23.3.8</strong><br>比较SSIM中不同检测方法的优劣<br>result_no1：没有填充的图像，无高斯加权，未进行阈值去噪<br>result_no2：没有填充的图像，高斯加权，未进行阈值去噪<br>result_no3：没有填充的图像，无高斯加权，进行阈值去噪<br>result_no4：没有填充的图像，高斯加权，进行阈值去噪</p><p>result_fb1：按宽边填充的图像，无高斯加权，未进行阈值去噪<br>result_fb2：按宽边填充的图像，高斯加权，未进行阈值去噪<br>result_fb3：按宽边填充的图像，无高斯加权，进行阈值去噪<br>result_fb4：按宽边填充的图像，高斯加权，进行阈值去噪</p><h2 id="day-55"><a href="#day-55" class="headerlink" title="day 55"></a>day 55</h2><p><strong>23.3.9</strong><br>发现找差异最小的mask_size效果比找差异最大的好<br>将数据放到GPU上运行，速度提升小<br>使用的模型为所有数据集训练得到的，包括异常数据集。<br>result_fbno1：按宽边填充的图像，无高斯加权，未进行阈值去噪<br>result_fbno2：按宽边填充的图像，高斯加权，未进行阈值去噪<br>result_fbno3：按宽边填充的图像，无高斯加权，进行阈值去噪<br>result_fbno4：按宽边填充的图像，高斯加权，进行阈值去噪</p><p>MAE学习能力太强，当训练集中有异常数据时，重建时异常仍会被重建</p><h2 id="day-56"><a href="#day-56" class="headerlink" title="day 56"></a>day 56</h2><p><strong>23.3.10</strong><br>重建效果最好：result_fb1、差异最小的<br>检测效果最好：<br>似乎不需要多尺度，以16为mask_size的效果更好<br>未进行填充的数据集对于遮挡的效果差</p><h2 id="day-57"><a href="#day-57" class="headerlink" title="day 57"></a>day 57</h2><p><strong>23.3.13</strong><br>检测时，多尺度相似图的累积计算，或多inputsize累计计算<br>修改损失函数为SSIM进行实验<br>继续找无监督算法<br>开始将自己的算法用于MVTec上<br>开始比较其他算法：<br>US-Uninformed Students: Student–Teacher Anomaly Detection with Discriminative Latent Embeddings<br>KDAD-Multiresolution Knowledge Distillation for Anomaly Detection<br>STFPM-Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection<br>RIAD-Reconstruction by Inpainting for Visual Anomaly Detection<br>RD4AD-Anomaly Detection via Reverse Distillation from One-Class Embedding<br>RegAD-Registration based Few-Shot Anomaly Detection<br>UniAD-A Unified Model for Multi-class Anomaly Detection</p><h2 id="day-58"><a href="#day-58" class="headerlink" title="day 58"></a>day 58</h2><p><strong>23.3.14</strong><br>解决无监督问题——直接放进讨论中（余弦相似度）<br>多尺度问题——先不考虑多尺度，也可放进讨论中<br>只考虑图像级的评价指标，使用斜框IOU计算<br>和先前的方法对比：选择RIAD、STFPM</p><h2 id="day-59"><a href="#day-59" class="headerlink" title="day 59"></a>day 59</h2><p><strong>23.3.15</strong><br>重新整理标注数据集，在正方形框内标注</p><h2 id="day-60"><a href="#day-60" class="headerlink" title="day 60"></a>day 60</h2><p><strong>23.3.16</strong><br>图像级ROCAUC：<br>有缺陷为1，无缺陷为0<br>异常图找最大值组成list求ROCAUC<br>直接像素级求ROCAUC：<br>制作ground truth</p><h1 id="day-61"><a href="#day-61" class="headerlink" title="day 61"></a>day 61</h1><p><strong>23.3.17</strong><br>制作GT</p><h1 id="day-62"><a href="#day-62" class="headerlink" title="day 62"></a>day 62</h1><p><strong>23.3.18</strong><br>完成图像级和像素级ROCAUC等指标的计算，效果挺好的。</p><h1 id="day-63"><a href="#day-63" class="headerlink" title="day 63"></a>day 63</h1><p><strong>23.3.19</strong><br>重新完成了新数据集的训练、测试工作，评价指标依旧挺高的，说明的我们等方法效果确实挺好的</p><h1 id="day-64"><a href="#day-64" class="headerlink" title="day 64"></a>day 64</h1><p><strong>23.3.20</strong><br>调RIAD、STFPM两个代码<br>STFPM的检测效果比我们的效果差，但指标很高，原因：没进行裁剪直接计算像素级的指标，填充部分肯定都检测正常<br>修改后，像素级仍比我们的方法高，图像级要低<br>RIAD代码需要另找</p><h1 id="day-65"><a href="#day-65" class="headerlink" title="day 65"></a>day 65</h1><p><strong>23.3.21</strong><br>原代码集成指标计算<br>修改论文</p><h1 id="day-66"><a href="#day-66" class="headerlink" title="day 66"></a>day 66</h1><p><strong>23.3.22</strong><br>继续修改论文结构，基本确定标题框架，之后只差部分图片、实验和分析<br>对于RIAD论文代码调不通，选择新的方法，一篇同样基于transformer重建的论文方法(InTra)，代码已调通，只是训练很慢，调参麻烦</p><h1 id="day-67-69"><a href="#day-67-69" class="headerlink" title="day 67-69"></a>day 67-69</h1><p><strong>23.3.23-3.25</strong><br>不局限于重建方法，改用其他异常检测代码<br>继续挑选可以实现对代码，写论文</p><h1 id="day-70"><a href="#day-70" class="headerlink" title="day 70"></a>day 70</h1><p><strong>23.3.26</strong><br>基本完成比较实验，梳理还需要的内容：</p><ul><li>1、FastFlow图？暂时可不用</li><li>2、多尺度每一项指标(完成)</li><li>3、多尺度图</li><li>4、MVTec实验</li><li>5、讨论部分两种完全无监督方法的指标和图，先只采用224(完成all)</li><li>6、多阶段序列重建指标和图</li><li>7、修改检测代码<h1 id="day-71"><a href="#day-71" class="headerlink" title="day 71"></a>day 71</h1><strong>23.3.27</strong><br>多尺度完成<h1 id="day-72SAC"><a href="#day-72SAC" class="headerlink" title="day 72SAC"></a>day 72SAC</h1><strong>23.3.28</strong><br>代码修改完成，大大提升了速度<br>讨论部分完成两种完全无监督方法的指标和图，先只采用224<br>对前面文字进行了修改<h1 id="day-73"><a href="#day-73" class="headerlink" title="day 73"></a>day 73</h1><strong>23.3.29</strong><br>完成所有实验<br>完成论文初稿<h1 id="day-74"><a href="#day-74" class="headerlink" title="day 74"></a>day 74</h1><strong>23.3.30</strong><br>修改论文<br>开始在MVTec上测试<h1 id="day-75"><a href="#day-75" class="headerlink" title="day 75"></a>day 75</h1><strong>23.3.31</strong><br>完成测试<br>论文中增加MVTec的分析<h1 id="day-76-79"><a href="#day-76-79" class="headerlink" title="day 76-79"></a>day 76-79</h1><strong>23.4.10-23.4.13</strong><br>修改润色论文<h1 id="day-80"><a href="#day-80" class="headerlink" title="day 80"></a>day 80</h1><strong>23.4.14</strong><br>已投稿</li></ul>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 记录 </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重学python</title>
      <link href="/2022/09/06/study/python/"/>
      <url>/2022/09/06/study/python/</url>
      
        <content type="html"><![CDATA[<p><strong>基于一个<a href="https://github.com/jackfrued/Python-100-Days.git">GitHub项目</a>学习</strong></p><h2 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h2><p>1、环境配置<br><code>python 3.10</code></p><p>2、输入<code>import this</code>运行程序</p><blockquote><p>输出：<br><code>The Zen of Python, by Tim Peters</code><br><code>Beautiful is better than ugly.</code><br><code>Explicit is better than implicit.</code><br><code>Simple is better than complex.</code><br><code>Complex is better than complicated.</code><br><code>Flat is better than nested.</code><br><code>Sparse is better than dense.</code><br><code>Readability counts.</code><br><code>Special cases aren&#39;t special enough to break the rules.</code><br><code>Although practicality beats purity.</code><br><code>Errors should never pass silently.</code><br><code>Unless explicitly silenced.</code><br><code>In the face of ambiguity, refuse the temptation to guess.</code><br><code>There should be one-- and preferably only one --obvious way to do it.</code><br><code>Although that way may not be obvious at first unless you&#39;re Dutch.</code><br><code>Now is better than never.</code><br><code>Although never is often better than *right* now.</code><br><code>If the implementation is hard to explain, it&#39;s a bad idea.</code><br><code>If the implementation is easy to explain, it may be a good idea.</code><br><code>Namespaces are one honking great idea -- let&#39;s do more of those!</code></p></blockquote><p>3、<code>turtle</code>库的使用</p><p>4、变量与类型</p><blockquote><p>使用<code>type()</code>检查变量的类型<br>使用<code>input()</code>函数获取键盘输入(字符串)<br>使用<code>int()</code>将一个数值或字符串转换成整数，可以指定进制。<br>使用<code>float()</code>将一个字符串转换成浮点数。<br>使用<code>str()</code>将指定的对象转换成字符串形式，可以指定编码。<br>使用<code>chr()</code>将整数转换成该编码对应的字符串（一个字符）。<br>使用<code>ord()</code>将字符串（一个字符）转换成对应的编码（整数）</p></blockquote><p>5、占位符<br><code>%d、%.nf(n表示n位小数)、%s</code><br>如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;对应的摄氏温度为：%.6f&quot;</span> % b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;对应的摄氏温度为：<span class="subst">&#123;b:<span class="number">.6</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></p><h2 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h2><p>1、<code>print(&quot;内容&quot;, end=&#39; &#39;)</code><br><code>end=&#39;&#39;</code>是设置<code>print()</code>打印结束添加的字符，如打印九九乘法表：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, i+<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%d * %d = %d&quot;</span> % (j, i, i * j), end=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure></p><p>2、执行代码模块<code>__main__</code></p><p><code>__name__</code>是<code>python</code>中一个隐含的变量它代表了模块的名字，只有被<code>python</code>解释器直接执行的模块的名字才是<code>__main__</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># add code</span></span><br></pre></td></tr></table></figure><br>3、变量的作用域<br><code>global</code>关键字来指示函数中的变量来自于全局作用域，如果全局作用域中没有该变量，那么下面一行的代码就会定义该变量并将其置于全局作用域。<br>同理，如果我们希望函数内部的函数能够修改嵌套作用域中的变量，可以使用<code>nonlocal</code>关键字来指示变量来自于嵌套作用域。<br>如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="comment"># global a</span></span><br><span class="line">    a = <span class="number">20</span></span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    func()</span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">20</span></span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># a = 2</span></span><br><span class="line">    func()</span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 20</span></span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">20</span></span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    func()</span><br><span class="line">    <span class="built_in">print</span>(a)  <span class="comment"># 20</span></span><br></pre></td></tr></table></figure></p><h2 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h2><p>1、<code>break</code>和<code>continue</code>的用法<br><code>break</code>能且只能终止它所在的那个循环，<code>continue</code>可以用来放弃本次循环后续的代码直接让循环进入下一轮，而不是跳出循环，这一点在使用嵌套的循环结构需要引起注意。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VS2022中Opencv的配置</title>
      <link href="/2022/08/27/teach/vs-opencv/"/>
      <url>/2022/08/27/teach/vs-opencv/</url>
      
        <content type="html"><![CDATA[<h1 id="VS2022的下载与安装"><a href="#VS2022的下载与安装" class="headerlink" title="VS2022的下载与安装"></a>VS2022的下载与安装</h1><p><strong>1、下载</strong><br>进入<a href="https://visualstudio.microsoft.com/zh-hans/vs/">官网</a>下载VS2022社区版(Community)</p><div align="center"><img src="https://s2.loli.net/2022/09/02/wTNoas4ukDXbAdv.png" width="75%"></div><p><strong>2、安装VS</strong><br>主要是要修改安装位置。默认是C盘，由于安装空间大，所以最好安装到其他盘</p><div align="center"><img src="https://s2.loli.net/2022/09/02/JVu3oWIgGRi7ZOM.png"></div><p><strong>3、组件与工作负荷的选择</strong><br>对于只是用C++来说，仅仅选择C++桌面开发即可</p><div align="center"><img src="https://s2.loli.net/2022/09/02/cT3CHwqubD1pm5a.png"></div><p><strong>4、组件与工作负荷的扩展</strong><br>打开Visual Studio Installer</p><div align="center"><img src="https://s2.loli.net/2022/09/02/SOuLTzVDoAnh1p3.png"></div><p>点击修改即可重新回到3中的界面，继续选择需要安装的工作负荷与组件</p><div align="center"><img src="https://s2.loli.net/2022/09/02/y59bSUjDeZXtiIn.png"></div><h1 id="Opencv的下载与安装"><a href="#Opencv的下载与安装" class="headerlink" title="Opencv的下载与安装"></a>Opencv的下载与安装</h1><p><strong>1、下载</strong><br>进入<a href="https://opencv.org/releases/">官网</a>下载</p><div align="center"><img src="https://s2.loli.net/2022/09/02/MqLrCWxGKfp4dbB.png"></div><p>点击Windows进入下载界面</p><div align="center"><img src="https://s2.loli.net/2022/09/02/Ow7kPct8LosEvAn.png"></div><p>等待几秒后开始下载</p><p><strong>2、安装opencv</strong></p><p>下载完成后得到安装包</p><div align="center"><img src="https://s2.loli.net/2022/09/02/2qCVKWpLOBEJ1zx.png"></div><p>点击安装包开始安装，可以修改安装路径</p><div align="center"><img src="https://s2.loli.net/2022/09/02/Jarql8PLvhZCbWx.png"></div><p>安装完成后，得到opencv文件夹</p><div align="center"><img src="https://s2.loli.net/2022/09/02/6SDV8Qt4rI7GmoR.png"></div><p><strong>3、环境变量配置</strong></p><p>在环境变量的系统变量中找到Path并打开</p><div align="center"><img src="https://s2.loli.net/2022/09/02/8czEMLpqB4uGNA7.png"></div><p>将opencv的如下环境添加至Path中</p><div align="center"><img src="https://s2.loli.net/2022/09/02/Yt3fIP4pju1QiSL.png"></div><p><strong>4、添加动态链接库</strong></p><p>将3个.dll文件复制到C:\Windows\System32(个数不一定相同。文件名称格式一样就行)</p><div align="center"><img src="https://s2.loli.net/2022/09/02/ZwECXAD35vQKmRz.png"></div><p>将2个.dll文件复制到C:\Windows\SysWOW64(个数不一定相同。文件名称格式一样就行)</p><div align="center"><img src="https://s2.loli.net/2022/09/02/gK8XtsaHVTEpNL5.png"></div><p><strong>这样就完成了opencv库的安装</strong></p><h1 id="Opencv的配置"><a href="#Opencv的配置" class="headerlink" title="Opencv的配置"></a>Opencv的配置</h1><p><strong>1、新建项目</strong></p><p>打开VS2022，新建项目</p><div align="center"><img src="https://s2.loli.net/2022/09/02/nAZH5Q3j7LFfkiz.png"></div><p>选择C++、Windows平台创建新的项目文件</p><p><strong>2、新建属性表</strong></p><p>在“视图→其他窗口→属性管理器”打开属性管理器，在Debug|x64中添加新的项目属性表(可以新建一个专门文件夹存放，属性表名称可改，后缀不能改)。</p><div align="center"><img src="https://s2.loli.net/2022/09/02/Iwe4hfXr5kon91Y.png"></div><div align="center"><img src="https://s2.loli.net/2022/09/02/AMfTQ2O93jcvgun.png"></div><p><strong>3、修改属性表内容</strong></p><p>点击属性页，修改VC++中的包含目录和库目录以及链接器→输入中的附加依赖项</p><div align="center"><img src="https://s2.loli.net/2022/09/02/bJo7p36wldcnZBq.png"></div><p>包含目录新增：</p><blockquote><p><code>opencv\build\include</code><br><code>opencv\build\include\opencv2</code></p></blockquote><p>库目录新增：</p><blockquote><p><code>opencv\build\x64\vc15\lib</code></p></blockquote><p>附加依赖项新增：</p><blockquote><p><code>opencv_world460d.lib</code><br><code>opencv_world460.lib</code></p></blockquote><p><strong>4、点击确定保存属性表</strong></p><h1 id="Opencv的使用"><a href="#Opencv的使用" class="headerlink" title="Opencv的使用"></a>Opencv的使用</h1><p>在其他新的项目中使用，只需点击属性管理器的Debug|x64，添加已有项目属性表，将前面新建的opencv属性表添加进属性管理器即可使用opencv库</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> opencv </tag>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于anoconda的python环境搭建与版本控制</title>
      <link href="/2022/08/26/teach/anaconda/"/>
      <url>/2022/08/26/teach/anaconda/</url>
      
        <content type="html"><![CDATA[<h1 id="Anacoda安装"><a href="#Anacoda安装" class="headerlink" title="Anacoda安装"></a>Anacoda安装</h1><p><strong>1、下载安装</strong><br>前往<a href="https://www.anaconda.com/">官网</a>进行下载，有时候官网下载很慢，可以前往国内<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/">镜像源</a>下载，下载完后自行安装即可。<br> <strong>2、添加环境变量</strong><br> Anaconda安装后，需要将以下路径添加到环境变量中，重启电脑后生效。</p><div align="center"><img src = "https://s2.loli.net/2022/11/12/OaITwf1roAkjG9S.png" width="50%"></div><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p><strong>1、新建环境</strong><br><code>conda create -n env_name python</code><br>(<code>env_name</code>为环境名称，<code>python</code>默认最新版本，需要特定版本使用<code>python=x.x</code>)</p><p><strong>2、查看环境</strong><br><code>conda info --envs</code>或<code>conda env list</code></p><p><strong>3、激活环境</strong><br><code>conda activate env_name</code><br>(<code>env_name</code>为环境名称，<code>conda</code>可以省略)</p><p><strong>4、退出环境</strong><br><code>conda deactivate</code><br>(<code>conda</code>有时可以省略)</p><p><strong>5、删除环境</strong><br><code>conda remove -n env_name --all</code></p><p><strong>6、切换镜像</strong><br>在安装<code>python</code>扩展包时经常用到<br><code>conda install pkgs_name -c channels</code><br>这里的channels是镜像网站的地址，对于下载访问速度慢的扩展包可以从镜像网站上下载。<br>常用的镜像网站channels有：</p><blockquote><p>channals:<br>清华源<br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/</a><br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/win-64/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/win-64/</a><br><a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a> </p></blockquote><p>阿里云<br><a href="https://mirrors.aliyun.com/anaconda/cloud/pytorch/win-64/">https://mirrors.aliyun.com/anaconda/cloud/pytorch/win-64/</a><br><a href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a></p><p>北外<br><a href="https://mirrors.bfsu.edu.cn/anaconda/cloud/pytorch/win-64/">https://mirrors.bfsu.edu.cn/anaconda/cloud/pytorch/win-64/</a><br><a href="https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/win-64/">https://mirrors.bfsu.edu.cn/anaconda/pkgs/main/win-64/</a></p><p>南京大学<br><a href="https://mirrors.nju.edu.cn/pub/anaconda/cloud/pytorch/win-64/">https://mirrors.nju.edu.cn/pub/anaconda/cloud/pytorch/win-64/</a></p><p>豆瓣<br><a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a></p><p>中国科技大学<br><a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a></p><p>基本上所有下载速度慢的包都能找到，可以自行在镜像网里面找，注意不同包可能要换镜像子地址。</p><p>另外，还可以直接修改默认channels，个人不太习惯这样做。</p><h1 id="jupyter安装"><a href="#jupyter安装" class="headerlink" title="jupyter安装"></a>jupyter安装</h1><p><strong>1、打开jupyter notebook</strong><br><code>win+R</code>打开终端，输入<code>jupyter notebook</code></p><p><strong>2、修改jupyter notebook默认目录</strong><br>在终端输入<br><code>jupyter notebook --generate-config</code><br>生成<code>C:\Users\XXX\.jupyter\jupyter_notebook_config.py</code>文件</p><p>打开<code>jupyter_notebook_config.py</code>文件，修改<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## The directory to use for notebooks and kernels.</span></span><br><span class="line"><span class="comment">#  Default: &#x27;&#x27;</span></span><br><span class="line"><span class="comment">#  c.NotebookApp.notebook_dir = &#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br>为(大概在300-400行)：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## The directory to use for notebooks and kernels.</span></span><br><span class="line"><span class="comment">#  Default: &#x27;&#x27;</span></span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">&#x27;F:\APP\Jupyter&#x27;</span></span><br></pre></td></tr></table></figure></p><p>最后删除<code>jupyter notebook</code>属性中目标后缀 <code>&quot;%USERPROFILE%/&quot;</code></p><div align="center"><img src = "https://s2.loli.net/2022/09/02/kQ27ibD8mZlNCF9.png" width="60%"></div><p><strong>3、添加内核</strong><br>切换到要添加的虚拟环境</p><blockquote><p><code>conda activate env_name</code><br>(<code>env_name</code>为环境名称，<code>conda可</code>以省略)</p></blockquote><p>安装<code>ipykernel</code></p><blockquote><p><code>python -m pip install ipykernel</code></p></blockquote><p>为<code>jupyter</code>添加内核(<code>env_name</code>为环境名称）</p><blockquote><p><code>python -m ipykernel install --user --name env_name</code></p></blockquote><p><strong>4、查看jupyter内核</strong><br><code>jupyter kernelspec list</code></p><p><strong>5、切换内核</strong><br>直接<code>jupyter notebook</code>界面Kernel中Change Kernel，选择需要的内核即可。</p><div align="center"><img src = "https://s2.loli.net/2022/09/02/dEAhebRorjLNP5w.png" width="75%"></div><p><strong>6、删除内核</strong><br><code>jupyter kernelspec remove kernelname</code></p><h1 id="pytorch的安装"><a href="#pytorch的安装" class="headerlink" title="pytorch的安装"></a>pytorch的安装</h1><p><strong>1、虚拟环境中python扩展包的安装</strong></p><p>切换到要添加的虚拟环境(<code>env_name</code>为环境名称，<code>conda</code>可以省略)</p><blockquote><p><code>conda activate env_name</code></p></blockquote><p>安装扩展包</p><blockquote><p><code>pip install pkg_names</code>或者<code>conda install pkg_names</code></p></blockquote><p>查看已安装的扩展包</p><blockquote><p><code>pip list</code>或者<code>conda list</code></p></blockquote><p><strong>2、pytorch的安装</strong><br>使用<code>nvidia-smi</code>查看自己的<code>cuda</code>版本<br>安装对应的<a href="https://developer.nvidia.com/cuda-toolkit-archive">cuda</a>(安装过程中把Visual Studio Integration的勾选去掉)和<a href="https://developer.nvidia.com/cudnn">cudnn</a>(需要注册)，具体可参考<a href="https://blog.csdn.net/Jin1Yang/article/details/124754015">链接</a><br><code>pytorch</code>仍然是扩展包，可以使用<code>conda install pkg_names</code>安装。具体可参考<a href="https://pytorch.org/get-started/locally/">pytorch官网</a></p><p><code>conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge</code></p><p>但由于pytorch要从国外下载，速度慢，所以需要用前面的镜像网站。<br>如yolov5的pytorch环境搭建：<br><code>conda install pytorch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0 cudatoolkit=11.3 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/</code><br>同样可以修改扩展包的版本。</p><p><strong>3、pytorch安装完成检验</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><br>输出为<code>True</code>则表示pytorch安装完成。<br>到此为止仅仅只是pytorch安装正确，不一定能使用，可能会出现GPU算力与cuda版本不匹配的情况，如我在服务器3090显卡上跑程序，出现：<br><code>GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.</code>报错，则说明cuda版本有问题，需要重新装正确的pytorch包。<br>最终测试cuda版本torch是否可用可以使用代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.zeros(<span class="number">1</span>).cuda()</span><br></pre></td></tr></table></figure><br>输出为<code>tensor([0.], device=&#39;cuda:0&#39;)</code>则表示pytorch可以正常使用了。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> python </tag>
            
            <tag> anoconda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5源代码学习与调试</title>
      <link href="/2022/08/12/study/yolo/"/>
      <url>/2022/08/12/study/yolo/</url>
      
        <content type="html"><![CDATA[<p>Callbacks</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># na: number of anchors 每一个predict head上的anchor数 = 3</span><br><span class="line">a = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors</span><br><span class="line"># no: number of outputs 每一个predict head层的输出channel = anchors * (classes + 5) = 75(VOC)</span><br><span class="line">no = na * (nc + 5)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Model(cfg or ckpt[&#x27;model&#x27;].yaml, ch=3, nc=nc, anchors=hyp.get(&#x27;anchors&#x27;)).to(device)  # create</span><br><span class="line">中hyp.get(&#x27;anchors&#x27;)？？？</span><br></pre></td></tr></table></figure><p>8.12 # Trainloader</p><h2 id="yolov5-mask项目调试"><a href="#yolov5-mask项目调试" class="headerlink" title="yolov5_mask项目调试"></a>yolov5_mask项目调试</h2>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> detection </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>“2”开头的第一年</title>
      <link href="/2022/05/31/life/birth21/"/>
      <url>/2022/05/31/life/birth21/</url>
      
        <content type="html"><![CDATA[<font size=6><center>“2”开头的第一年</center></font><p>2021.6.1，我20岁。<br>2022.6.1，我21了。<br>在20岁的在这一年里，发生了很多事，有好有坏，总的来说，好&gt;坏。<br>先按时间顺序写写吧。</p><p>6月印象：打针+考试<br>前一天晚上：真好吃<br>第二天白天：真难受<br>（<strong>切勿暴饮暴食</strong>）</p><center class = "half"><figure><img src = "https://s2.loli.net/2022/06/02/cSbJEXIvGkAWfy8.jpg" width = "45%" align = left><img src = "https://s2.loli.net/2022/06/02/fEuwh2peNaACOFj.jpg" width = "45%" align = right/></figure></center>考试就不BB了。<br/><br/>7月印象：社会实践两次社会实践，走出去看到了很多。看到这样的教室，慕了:cry:<center class = "half"><img src = "https://s2.loli.net/2022/06/02/B7kYnE3WcqJXi2Z.jpg" width = "70%" align = center/></center>第一次在现场看升旗，前一天晚上高铁延误推迟近两小时才到，第二天早上3、4点起床，不如不睡。（幸好去得早，站在一个很靠前的位置）<center class = "half"><img src = "https://s2.loli.net/2022/06/02/3gUGNA7dmzsltvR.jpg" width = "60%" align = center/></center><p>8月印象：暑假+长肉<br>搞了一个暑假群智能，当时被画饼，以为能搞出啥，现在看纯纯沙贝:rage:（后面再骂）</p><p>9月印象：换宿舍+军训办<br>9月开学，一件大事发生——我换宿舍了。说实话，我当时暑假是近乎于求着xxx换宿舍，现在回想起来自己都感到恶心，但这宿舍换得好啊，直接nice！<br>正因为换了宿舍，我遇到了3个和我一样 <del>帅气</del>（沙贝）的人——C、L、Z（按首字母顺序排序:sweat_smile:），这就是这一年真正的开始。<br>说实话，大学三年了，前两年和C、L真不熟，差不多仅是工作上的往来吧。和Z还是比较熟的，日常panagiu:basketball:、实验组队等，但是由于当时4个人4栋楼，交际仅限于上课时间。但宿舍一换，这一年直接gao（感觉这词有点恰当）一起。<br>9月还评选了奖学金，有些事就不在这说了吧。。。<br>附一张国奖大佬吧。</p><center class = "half"><img src = "https://s2.loli.net/2022/06/03/yoKkLWC9nwqXjQT.jpg" width = "60%" align = center/></center>太帅了！！！至于军训办就是看着新生军训，给他们做后勤保障。虽然很累，但有:moneybag:，还是很不戳滴！负责开学典礼的摆字，看效果感觉不错。<center class = "half"><img src = "https://s2.loli.net/2022/06/03/Jd1E8RcTn7wlIOU.jpg" width = "60%" align = center/></center><br/><br/>10月印象：吃吃喝喝感觉一整个月没干啥事，吃吃喝喝玩玩就过完了。好像是当时很久没喝了。<center class = "half"><img src = "https://s2.loli.net/2022/06/03/aphNytYoFIfXDse.jpg" width = "60%" align = center/></center>第一次晚到校门被锁才回学校。<center class = "half"><img src = "https://s2.loli.net/2022/06/03/wBDoI3sY4AljLmZ.jpg" width = "60%" align = center/></center><p>11月印象：考试吧，没啥印象了</p><p>12月印象：正式党员</p><center class = "half"><img src = "https://s2.loli.net/2022/06/03/Xmt95OzShZoUGfw.jpg" width = "60%" align = center/></center><p>1月印象：回家+寒假<br>三天一小会，五天一大会，开个鬼的会，沙贝:rage:</p><p>2月印象：下大雪+开学美赛<br>似乎好多年没看到这样的大雪了！</p><center class = "half"><img src = "https://s2.loli.net/2022/06/03/OtkwvihRH7Zx3nd.jpg" width = "60%" align = center/></center><p>为了打美赛，提前来学校。第一次打数模，熬了两三天，东西出来了，但个人觉得很拉（现在结果出来了，确实很拉:joy:）</p><p>3月印象：封楼+过山车<br>由于宿舍楼栋有密接，所以楼栋被封控。说实话，除了不能出去，其他的倒还是蛮舒服的:joy:</p><center class = "half"><img src = "https://s2.loli.net/2022/06/03/n9tQ3dM4TN6Pfr2.jpg" width = "60%" align = center/></center><p>由于我们这一级很卷，以至于今年找研究生导师提前了很多很多，感谢L提供的信息，我从去年放假前就找了一位导师G，他说开学之后再面试一下。2月份和他见了面，聊了一些，面试结束的时候说之后<strong>他</strong>找时间确定一下之后的细节，我当时以为稳了，还在他那报了大创。可是，我等了一个月，没信，之后听说他那人满了，我再次找到他表明自己的意愿，好家伙，被拒了。理由是，我没及时联系他。tmd面试的时候是你说你找时间，现在又是我自己的问题。当时直接麻了，整个人都是懵的，但没办法，只能找其他的老师。那天中午，我一口气联系了5名老师，还好，当天下午就有老师回复了，也聊了，怎么说是有书可以读了。之后所有的老师都聊过了，现在也已经基本上确定导师了。<br>这一天，心里直接过山车，那种低气压的感受贼不舒服，据L说，当时他在宿舍吃东西都不敢大声，sorry啦！</p><p>4月印象：开摆</p><center class = "half"><img src = "https://s2.loli.net/2022/06/04/Ew9r68RPHAOlmKU.jpg" width = "60%" align = center/></center><p>找导师的事情基本上已经是尘埃落定，4月就开始放松了，出去玩的次数多了，顺便给电脑清了个灰，买了这么久第一次打扫打扫。对了，清灰的那天准备剧本杀的，然而我们直接来了个“现实杀”。当时我们坐出租去清灰的地方，刚下车，突然听到一声“wc”，Z说他手机掉车上了，于是那个下午，我们就开始找手机之旅。最后是找到了，但微信转账“三 百 块”。还第一次亲身感受到了报警（虽然没用到警察叔叔）。</p><p>长这么大第一次亲眼看到四叶草。</p><center class = "half"><img src = "https://s2.loli.net/2022/06/04/hM4T9tK8ioJQS5D.jpg" width = "60%" align = center/></center><p>对了对了，写着写着差点忘了，前面一直想骂，忘记骂了，我就搞不懂了，怎么就会遇到这样的老师，从去年暑假就在做的群智能 一个项目，通过一个学期加一个寒假，论文城成果基本上已经出来了，整个工作基本上是两个人完成的，但是，就是有这么恶心的老师，作者排序的时候就完全他自己决定了，不考虑工作量了？一个屁事都没怎么干的人，凭什么拿一作，就凭你，你是个什么够吧玩意儿。最恶心的是啥，去找他改作者顺序，直接把我支走，什么东西啊，一天到晚狗一样叫唤，沙贝！！！！！<br>虽然我现在不是特别需要这篇文章，但是也不能这么瞎搞吧，md配做老师吗？？</p><p>5月印象：剧本杀+实验<br>这个月实验是真的多</p><center class = "half"><img src = "https://s2.loli.net/2022/06/04/NrK93vzQZLc7mGP.jpg" width = "45%" align = left><img src = "https://s2.loli.net/2022/06/04/JojL5H4zGIqCn1a.jpg" width = "45%" align = right/></center><p>但其它课很少了，所以就真的出去开“杀”了。第一次体验，还算不错，就环境不太好，但起码过程还行。（忘记拍照了:joy:）。第二次，就不太行，虽然环境好了一些，但体验贼差，还拿了凶手牌，那dm还不知道在干啥，无语，整个本似乎也没有特别高能的地方，害:sweat:。</p><center class = "half"><img src = "https://s2.loli.net/2022/06/04/GeyVSrWT91oDEqd.jpg" width = "60%" align = center/></center><p>这一年差不多就这些事吧，本来不想写的，但想着还是记录一下比较好吧，就这样吧，下一年，继续gogo！</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 记录， 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缺陷检测综述</title>
      <link href="/2022/04/26/study/defect%20detection/"/>
      <url>/2022/04/26/study/defect%20detection/</url>
      
        <content type="html"><![CDATA[<font size=8><center>视觉缺陷检测方法综述</center></font><h1 id="图像获取"><a href="#图像获取" class="headerlink" title="图像获取"></a>图像获取</h1><p>组成：CCD摄像机、光学镜头、光源、夹持装置等。</p><p>光信号转换成电信号再转换成数字信号。</p><h1 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h1><h2 id="图像去噪"><a href="#图像去噪" class="headerlink" title="图像去噪"></a>图像去噪</h2><p>图像噪声对<br>后续的图像处理影响很⼤， 它影响图像处理的各个环节以及输出结果，因此， 在对图像处理前， 需要对待检测图像进⾏去噪处理，具体的方法有：</p><ul><li>数学形态学方法</li><li>小波方法</li></ul><h2 id="图像增强"><a href="#图像增强" class="headerlink" title="图像增强"></a>图像增强</h2><p>图像增强是指有⽬的地强调图像的整体或局部特性， 将原来不清晰的图像变得清晰或强调某些感兴趣的特征， 扩⼤图像中不同物体特征之间的差别， 抑制不感兴趣的特征， 使之改善图像质量、丰富信息量， 加强图像判读和识别效果的图像处理⽅法。</p><h2 id="图像复原"><a href="#图像复原" class="headerlink" title="图像复原"></a>图像复原</h2><p>图像复原是通过计算机处理， 对质量下降的图像加以重建或复原的处理过程。</p><h2 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h2><p>图像分割的⽬的是把图像中⽬标区域分割出来， 以便进⾏下⼀步的处理。</p><h3 id="基于区域的分割方法"><a href="#基于区域的分割方法" class="headerlink" title="基于区域的分割方法"></a>基于区域的分割方法</h3><ul><li>阈值分割法：通过设定不同的灰度阈值， 把图像像素点分为若⼲类。<br>具体方法有：固定阈值法、⾃适应阈值法、多区域阈值法等。</li><li>区域生长法：依据⼀定的⽣⻓准则， 将若⼲个相似⼦区域聚合成较⼤的区域</li><li>分裂——合并法：根据图像和各区域的不均匀性， 将图像或区域分裂成新的⼦区域， 再将包含相同内容的区域合并成新的较⼤区域， 最后得到分割图像。<br>具体方法有：四叉树分解法等。</li><li>聚类分割法：根据图像在特征空间的聚集对特征空间进⾏分割， 再映射到原图像空间得到分割结果。<br>具体方法有：K均值聚类算法、模糊C均值聚类(FCM)算法等。<h3 id="基于边缘的分割方法"><a href="#基于边缘的分割方法" class="headerlink" title="基于边缘的分割方法"></a>基于边缘的分割方法</h3></li></ul><h3 id="基于特定理论的分割方法"><a href="#基于特定理论的分割方法" class="headerlink" title="基于特定理论的分割方法"></a>基于特定理论的分割方法</h3><h1 id="图像分析"><a href="#图像分析" class="headerlink" title="图像分析"></a>图像分析</h1><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><h3 id="纹理特征提取"><a href="#纹理特征提取" class="headerlink" title="纹理特征提取"></a>纹理特征提取</h3><h4 id="统计法"><a href="#统计法" class="headerlink" title="统计法"></a>统计法</h4><ul><li>直方图特征</li><li>灰度共生矩</li><li>局部二值模式(LBP)</li><li>自相关函数<h4 id="信号处理法"><a href="#信号处理法" class="headerlink" title="信号处理法"></a>信号处理法</h4></li><li>傅里叶变换</li><li>Gabor滤波</li><li>小波变换</li><li>Laws纹理<h4 id="结构法"><a href="#结构法" class="headerlink" title="结构法"></a>结构法</h4></li></ul><h4 id="模型法"><a href="#模型法" class="headerlink" title="模型法"></a>模型法</h4><ul><li>马尔可夫随机场模型(MRF)</li><li>分型模型</li><li>自回归模型<h3 id="形状特征提取"><a href="#形状特征提取" class="headerlink" title="形状特征提取"></a>形状特征提取</h3><h4 id="基于区域的特征提取"><a href="#基于区域的特征提取" class="headerlink" title="基于区域的特征提取"></a>基于区域的特征提取</h4></li><li>⼏何特征</li><li>拓扑结构特征</li><li>矩特征<h4 id="基于轮廓的特征提取"><a href="#基于轮廓的特征提取" class="headerlink" title="基于轮廓的特征提取"></a>基于轮廓的特征提取</h4></li><li>边界特征法(边界形状数、边界矩等)</li><li>简单⼏何特征(如周⻓、半径、曲率、边缘夹⻆)</li><li>基于变换域(如傅⾥叶描述符、⼩波描述符)</li><li>曲率尺度空间(CSS)</li><li>数学形态学</li><li>霍夫变换</li><li>⼩波描述符等<h3 id="颜色特征提取"><a href="#颜色特征提取" class="headerlink" title="颜色特征提取"></a>颜色特征提取</h3><h4 id="颜色直方图"><a href="#颜色直方图" class="headerlink" title="颜色直方图"></a>颜色直方图</h4><h4 id="颜色集"><a href="#颜色集" class="headerlink" title="颜色集"></a>颜色集</h4><h4 id="颜色矩"><a href="#颜色矩" class="headerlink" title="颜色矩"></a>颜色矩</h4><h4 id="颜色聚合向量"><a href="#颜色聚合向量" class="headerlink" title="颜色聚合向量"></a>颜色聚合向量</h4></li></ul><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="主成分分析法-PCA"><a href="#主成分分析法-PCA" class="headerlink" title="主成分分析法(PCA)"></a>主成分分析法(PCA)</h3><h3 id="独⽴成分分析法-ICA"><a href="#独⽴成分分析法-ICA" class="headerlink" title="独⽴成分分析法(ICA)"></a>独⽴成分分析法(ICA)</h3><h3 id="Fisher分析法-FDA"><a href="#Fisher分析法-FDA" class="headerlink" title="Fisher分析法(FDA)"></a>Fisher分析法(FDA)</h3><h3 id="相关分析法-CFS"><a href="#相关分析法-CFS" class="headerlink" title="相关分析法(CFS)"></a>相关分析法(CFS)</h3><h3 id="⾃组织映射法-SOM"><a href="#⾃组织映射法-SOM" class="headerlink" title="⾃组织映射法(SOM)"></a>⾃组织映射法(SOM)</h3><h3 id="Relief法"><a href="#Relief法" class="headerlink" title="Relief法"></a>Relief法</h3><h3 id="遗传算法-GA"><a href="#遗传算法-GA" class="headerlink" title="遗传算法(GA)"></a>遗传算法(GA)</h3><h3 id="模拟退⽕法"><a href="#模拟退⽕法" class="headerlink" title="模拟退⽕法"></a>模拟退⽕法</h3><h3 id="禁忌搜索法-Tabu"><a href="#禁忌搜索法-Tabu" class="headerlink" title="禁忌搜索法(Tabu)"></a>禁忌搜索法(Tabu)</h3><h3 id="基于流⾏的⾮线性降维⽅法"><a href="#基于流⾏的⾮线性降维⽅法" class="headerlink" title="基于流⾏的⾮线性降维⽅法"></a>基于流⾏的⾮线性降维⽅法</h3><h2 id="图像识别"><a href="#图像识别" class="headerlink" title="图像识别"></a>图像识别</h2><h3 id="统计模式识别"><a href="#统计模式识别" class="headerlink" title="统计模式识别"></a>统计模式识别</h3><h4 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h4><ul><li>基于概率统计的分类器</li><li>线性分类器</li><li>⼈⼯神经⽹络分类器</li><li>⽀持向量机<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4></li><li>划分⽅法</li><li>层次⽅法</li><li>密度⽅法</li><li>⽹格⽅法</li><li>图论算法</li><li>模型算法<h3 id="句法（结构）模式识别"><a href="#句法（结构）模式识别" class="headerlink" title="句法（结构）模式识别"></a>句法（结构）模式识别</h3></li></ul><h1 id="主要问题"><a href="#主要问题" class="headerlink" title="主要问题"></a>主要问题</h1><ol><li>受环境、光照、⽣产⼯艺和噪声等多重因素影响，检测系统的信噪⽐⼀般较低，微弱信号难以检出或不能与噪声有效区分；</li><li>对缺陷的描述不充分，缺陷的特征提取有效性不⾼，缺陷⽬标分割困难；同时，很难找到标准图像作为参照；</li><li>数据量庞⼤、冗余信息多、特征空间维度⾼，同时考虑到真正的机器视觉⾯对的对象和问题的多样性，从海量数据中提取有限缺陷信息的算法能⼒不⾜，实时性不⾼；</li><li>如何模拟⼈类⼤脑的信息处理功能去构建智能机器视觉系统还需要理论上的进⼀步研究；</li><li>在实际应⽤中准确率仍然与满⾜实际应⽤的需求尚有⼀定差距。</li></ol><h1 id="发展趋势"><a href="#发展趋势" class="headerlink" title="发展趋势"></a>发展趋势</h1><ol><li>研究视觉检测新理论和新⽅法，如发展主动视觉、增强视觉系统的智能学<br>习能⼒等；</li><li>结合视觉任务，引⼊先验⾼级知识的指导，同时将机器视觉、机器听觉、机器嗅觉、机器触觉等多信息相互融合，突破单⼀视觉信息的局限性；</li><li>研究更具鲁棒性的图像处理和分析算法 提⾼图像处理的有效性和和执⾏效率，降低算法的复杂度，提⾼识别的准确性；</li><li>研究完整3维场景重建⽅法；</li><li>采⽤统⼀⽽开放的标准，构建标准化、⼀体化和通⽤化的解决⽅案，标准化与个性化的进⼀步统⼀， 研发可靠性⾼#维护性好#便于不断完善和升级换代、⽹络化、⾃动化和智能化更⾼的机器视觉系统是今后的发展趋势。</li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h1 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h1><p><img src="![mind1.jpg](https://s2.loli.net/2022/04/26/DNfYOGRmh1pJQlB.jpg" alt="综述思维导图"></p><h1 id="具体细节后补！！"><a href="#具体细节后补！！" class="headerlink" title="具体细节后补！！"></a>具体细节后补！！</h1>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> defect </tag>
            
            <tag> detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基础网络架构</title>
      <link href="/2022/04/15/study/backbone%20network/"/>
      <url>/2022/04/15/study/backbone%20network/</url>
      
        <content type="html"><![CDATA[<h1 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h1><p>LeNet由2个卷积层和3个全连接层组成，每个卷积层之后有一个Sigmoid激活函数和一个AvgPool2d平均汇聚层，前两层全连接层之后也有一个Sigmoid激活函数。<br>具体模型架构如图：</p><div align="center"><img src="https://s2.loli.net/2022/04/12/gbHLmzsX6plwTN3.png" width="65%"><br>LeNet模型图</div><div align="center"><img src="https://s2.loli.net/2022/04/12/o8GwAdvHScxPang.jpg" width="20%"><br>LeNet网络架构图</div><p>基于pytorch实现LeNet网络的模型搭建如下：</p><h2 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        num_classes:分类的数量</span></span><br><span class="line"><span class="string">        in_channels:原始图像通道数,灰度图像为1,彩色图像为3</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.lenet = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">6</span>, kernel_size=<span class="number">5</span>),  <span class="comment"># (32 - 5) / 1 + 1 = 28   [3, 32, 32] -&gt; [6, 28, 28]</span></span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># 28 / 2 = 14   [6, 28, 28] -&gt; [6, 14, 14]</span></span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),  <span class="comment"># (14 - 5) / 1 + 1 = 10   [6, 14, 14] -&gt; [16, 10, 10]</span></span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), <span class="comment"># 10 / 2 = 5   [16, 10, 10] -&gt; [16, 5, 5]</span></span><br><span class="line">            nn.Flatten(), <span class="comment"># 展平</span></span><br><span class="line">            nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Sigmoid(),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, num_classes)) <span class="comment"># 不需要使用激活函数，因为softmax激活函数被嵌入在交叉熵函数中</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.lenet(x)</span><br><span class="line">        <span class="comment"># probas = F.softmax(output, dim=1)</span></span><br><span class="line">        <span class="keyword">return</span> output <span class="comment">#, probas</span></span><br></pre></td></tr></table></figure><h2 id="模型检验"><a href="#模型检验" class="headerlink" title="模型检验"></a>模型检验</h2><p>打印出各层的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">in_channels = <span class="number">3</span></span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, in_channels, <span class="number">32</span>, <span class="number">32</span>), dtype=torch.float32)</span><br><span class="line">net = LeNet(in_channels, num_classes)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net.lenet:</span><br><span class="line">  X = layer(X)</span><br><span class="line">  <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure><p>结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Conv2d output shape:  torch.Size([1, 6, 28, 28])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 6, 28, 28])</span><br><span class="line">AvgPool2d output shape:  torch.Size([1, 6, 14, 14])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 16, 10, 10])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 16, 10, 10])</span><br><span class="line">AvgPool2d output shape:  torch.Size([1, 16, 5, 5])</span><br><span class="line">Flatten output shape:  torch.Size([1, 400])</span><br><span class="line">Linear output shape:  torch.Size([1, 120])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 120])</span><br><span class="line">Linear output shape:  torch.Size([1, 84])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 84])</span><br><span class="line">Linear output shape:  torch.Size([1, 10])</span><br></pre></td></tr></table></figure></p><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p><em>后补</em></p><h2 id="模型检测"><a href="#模型检测" class="headerlink" title="模型检测"></a>模型检测</h2><p><em>后补</em></p><h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p>AlexNet与LeNet网络架构基本相似，只是AlexNet更深，使用了8层卷积神经网络（5个卷积层，3个最大汇聚层），并且使用的激活函数不再是Sigmoid而是ReLU，其具体网络架构如下:</p><div align="center"><img src="https://s2.loli.net/2022/04/12/woAXRiu9qeG4l3P.jpg" width="35%"><br>LeNet架构图（左）AlexNet架构图（右）</div><p>基于pytorch实现AlexNet网络的模型搭建如下：</p><h2 id="模型建立-1"><a href="#模型建立-1" class="headerlink" title="模型建立"></a>模型建立</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        num_classes:分类的数量</span></span><br><span class="line"><span class="string">        in_channels:原始图像通道数,灰度图像为1,彩色图像为3</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.lenet = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),  <span class="comment"># (224 - 11 + 4) / 4 + 1 = 55.25   [3, 224, 224] -&gt; [96, 55, 55]</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),  <span class="comment"># (55 + 2 - 3) / 2 = 27   [96, 55, 55] -&gt; [96, 27, 27]</span></span><br><span class="line">            nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># (27 - 5 + 4) / 1 + 1 = 27   [96, 27, 27] -&gt; [256, 27, 27]</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># (27 - 3 + 2) / 2 = 13   [256, 27, 27] -&gt; [256, 13, 13]</span></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (13 - 3 + 2) / 1 + 1 = 13   [256, 13, 13] -&gt; [384, 13, 13]</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (13 - 3 + 2) / 1 + 1 = 13   [384, 13, 13] -&gt; [384, 13, 13]</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (13 - 3 + 2) / 1 + 1 = 13   [384, 13, 13] -&gt; [256, 13, 13]</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>), <span class="comment"># (13 - 3 + 2) / 2 = 6   [256, 13, 13] -&gt; [256, 6, 6]</span></span><br><span class="line">            nn.Flatten(), <span class="comment"># 展平</span></span><br><span class="line">            nn.Linear(<span class="number">256</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes)) <span class="comment"># 不需要使用激活函数，因为softmax激活函数被嵌入在交叉熵函数中</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.lenet(x)</span><br><span class="line">        <span class="comment"># probas = F.softmax(output, dim=1)</span></span><br><span class="line">        <span class="keyword">return</span> output <span class="comment">#, probas</span></span><br></pre></td></tr></table></figure><p>在第一次卷积操作时，不能完全便利整个图像，应该在左、上添两列零，右、下添一列零能完全遍历；使用padding=2填充，在操作过程中会自动省去多余数据，故影响不大。</p><h2 id="模型检验-1"><a href="#模型检验-1" class="headerlink" title="模型检验"></a>模型检验</h2><p>打印出各层的参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line">in_channels = <span class="number">3</span></span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, in_channels, <span class="number">224</span>, <span class="number">224</span>), dtype=torch.float32)</span><br><span class="line">net = AlexNet(in_channels, num_classes)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net.lenet:</span><br><span class="line">  X = layer(X)</span><br><span class="line">  <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure></p><p>结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Conv2d output shape:  torch.Size([1, 96, 55, 55])</span><br><span class="line">ReLU output shape:  torch.Size([1, 96, 55, 55])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 96, 27, 27])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 256, 27, 27])</span><br><span class="line">ReLU output shape:  torch.Size([1, 256, 27, 27])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 256, 13, 13])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 384, 13, 13])</span><br><span class="line">ReLU output shape:  torch.Size([1, 384, 13, 13])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 384, 13, 13])</span><br><span class="line">ReLU output shape:  torch.Size([1, 384, 13, 13])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 256, 13, 13])</span><br><span class="line">ReLU output shape:  torch.Size([1, 256, 13, 13])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 256, 6, 6])</span><br><span class="line">Flatten output shape:  torch.Size([1, 9216])</span><br><span class="line">Linear output shape:  torch.Size([1, 4096])</span><br><span class="line">ReLU output shape:  torch.Size([1, 4096])</span><br><span class="line">Dropout output shape:  torch.Size([1, 4096])</span><br><span class="line">Linear output shape:  torch.Size([1, 4096])</span><br><span class="line">ReLU output shape:  torch.Size([1, 4096])</span><br><span class="line">Dropout output shape:  torch.Size([1, 4096])</span><br><span class="line">Linear output shape:  torch.Size([1, 1000])</span><br></pre></td></tr></table></figure><h2 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h2><p><em>后补</em></p><h2 id="模型检测-1"><a href="#模型检测-1" class="headerlink" title="模型检测"></a>模型检测</h2><p><em>后补</em></p><h2 id="AlexNet与LeNet不同"><a href="#AlexNet与LeNet不同" class="headerlink" title="AlexNet与LeNet不同"></a>AlexNet与LeNet不同</h2><ul><li>网络更深，使用8层网络进行训练</li><li>激活函数改进，使用ReLU替代Sigmoid</li><li>池化层采用Maxpool2d代替Avgpool2d</li><li>在全连接层处使用Dropout丢弃法</li></ul><h1 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h1><h2 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h2><p>NiN块以⼀个普通卷积层开始，后⾯是两个$1 \times 1$的卷积层。这两个$1 \times 1$卷积层充当带有ReLU激活函数的逐像素全连接层。第⼀层的卷积窗口形状通常由⽤⼾<br>设置，随后的卷积窗口形状固定为$1 \times 1$。</p><p>所以NiN块可以定义为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nin</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class="line">    nin_block = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.ReLU())</span><br><span class="line">    <span class="keyword">return</span> nin_block</span><br></pre></td></tr></table></figure></p><p>NiN块和NiN的架构如下：</p><div align="center"><img src = "https://s2.loli.net/2022/04/12/MrzfdjGgRYlWV7k.png" width="50%"><br>VGG块及其网络架构（左）NiN块及其网络架构（右）</div><p>基于pytorch实现NiN网络的模型搭建如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">in_channels = <span class="number">1</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">nin_net = nn.Sequential(</span><br><span class="line">    nin(in_channels, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nin(<span class="number">384</span>, num_classes, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    nn.Flatten())</span><br></pre></td></tr></table></figure><h2 id="模型检验-2"><a href="#模型检验-2" class="headerlink" title="模型检验"></a>模型检验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(size=(in_channels, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">net = nin_net</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure><p>结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Sequential output shape:  torch.Size([1, 96, 54, 54])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 96, 26, 26])</span><br><span class="line">Sequential output shape:  torch.Size([1, 256, 26, 26])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 256, 12, 12])</span><br><span class="line">Sequential output shape:  torch.Size([1, 384, 12, 12])</span><br><span class="line">MaxPool2d output shape:  torch.Size([1, 384, 5, 5])</span><br><span class="line">Dropout output shape:          torch.Size([1, 384, 5, 5])</span><br><span class="line">Sequential output shape:  torch.Size([1, 10, 5, 5])</span><br><span class="line">AdaptiveAvgPool2d output shape:  torch.Size([1, 10, 1, 1])</span><br><span class="line">Flatten output shape:          torch.Size([1, 10])</span><br></pre></td></tr></table></figure><br>NiN使用分别使用了$11\times 11$、$5\times 5$和$3\times 3$的卷积核。每个NiN块后有一个最大池化层，核为$3\times 3$，步幅为2。</p><p>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。NiN使用的是一个NiN块，其输出通道数等于标签类别的数量。最后放一个<em>全局平均汇聚层</em>，生成一个<em>对数几率</em>。</p><p>NiN设计的一个优点是，它显著减少了模型所需参数的数量，但是有时会增加训练模型的时间。</p><h2 id="模型训练-2"><a href="#模型训练-2" class="headerlink" title="模型训练"></a>模型训练</h2><p><em>后补</em></p><h2 id="模型检测-2"><a href="#模型检测-2" class="headerlink" title="模型检测"></a>模型检测</h2><p><em>后补</em></p><h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><h2 id="VGG块"><a href="#VGG块" class="headerlink" title="VGG块"></a>VGG块</h2><p>VGG块与经典卷积神经网络一样，由一系列卷积层、激活函数和汇聚层组成，每一个VGG块只有卷积层个数、输入通道数和输出通道数不一样，所以，一个VGG块可以定义为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure><p>VGG神经网络就是由多个不同卷积层个数、输入通道数和输出通道数的VGG块共同组成卷积层，最后再连接3个全连接层组成整个神经网络，其架构如图所示：</p><div align="center"><img src = "https://s2.loli.net/2022/04/12/lr2zdoiLY5qActh.png" width = "75%"><br>AlexNet架构图（左）VGG块（中） VGG架构图（右）</div><p>基于pytorch实现AlexNet网络的模型搭建如下：</p><h2 id="模型建立-2"><a href="#模型建立-2" class="headerlink" title="模型建立"></a>模型建立</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vggnet</span>(<span class="params">conv, num_classes</span>):</span><br><span class="line">    conv_layers = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 调用VGG块定义卷积层模块</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv:</span><br><span class="line">        conv_layers.append(vgg_block(num_convs, in_channels, out_channels))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line"></span><br><span class="line">    net_vgg = nn.Sequential(</span><br><span class="line">        *conv_layers,</span><br><span class="line">        nn.Flatten(),</span><br><span class="line">        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> net_vgg</span><br></pre></td></tr></table></figure><p>定义不同的vgg块：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conv11 = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>)) <span class="comment"># VGG_11</span></span><br><span class="line">conv13 = ((<span class="number">2</span>, <span class="number">64</span>), (<span class="number">2</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>)) <span class="comment"># VGG_13</span></span><br><span class="line">conv16 = ((<span class="number">2</span>, <span class="number">64</span>), (<span class="number">2</span>, <span class="number">128</span>), (<span class="number">3</span>, <span class="number">256</span>), (<span class="number">3</span>, <span class="number">512</span>), (<span class="number">3</span>, <span class="number">512</span>)) <span class="comment"># VGG_16</span></span><br><span class="line">conv19 = ((<span class="number">2</span>, <span class="number">64</span>), (<span class="number">2</span>, <span class="number">128</span>), (<span class="number">4</span>, <span class="number">256</span>), (<span class="number">4</span>, <span class="number">512</span>), (<span class="number">4</span>, <span class="number">512</span>)) <span class="comment"># VGG_19</span></span><br><span class="line">num_classes = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">net = vggnet(conv16, num_classes)</span><br></pre></td></tr></table></figure></p><h2 id="模型检验-3"><a href="#模型检验-3" class="headerlink" title="模型检验"></a>模型检验</h2><p>构建一个高度和宽度为224的单通道数据样本，观察每个层输出的形状</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure><p>结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Sequential output shape:   torch.Size([1, 64, 112, 112])</span><br><span class="line">Sequential output shape:   torch.Size([1, 128, 56, 56])</span><br><span class="line">Sequential output shape:   torch.Size([1, 256, 28, 28])</span><br><span class="line">Sequential output shape:   torch.Size([1, 512, 14, 14])</span><br><span class="line">Sequential output shape:   torch.Size([1, 512, 7, 7])</span><br><span class="line">Flatten output shape:    torch.Size([1, 25088])</span><br><span class="line">Linear output shape:    torch.Size([1, 4096])</span><br><span class="line">ReLU output shape:    torch.Size([1, 4096])</span><br><span class="line">Dropout output shape:     torch.Size([1, 4096])</span><br><span class="line">Linear output shape:    torch.Size([1, 4096])</span><br><span class="line">ReLU output shape:     torch.Size([1, 4096])</span><br><span class="line">Dropout output shape:    torch.Size([1, 4096])</span><br><span class="line">Linear output shape:    torch.Size([1, 1000])</span><br></pre></td></tr></table></figure></p><p>在经过每一个VGG块后，图像高宽减半，通道数增加。从上面四个VGG模型可以看到，无论是VGG多少，都有5个VGG模块，而且这五个模块仅仅是num_convs不一样，每一个模块对应的out_channels是一样的。</p><p>由于VGG所含有的卷积层更多，网络更深，所以计算量比AlexNet更大，计算也慢很多。</p><h2 id="模型训练-3"><a href="#模型训练-3" class="headerlink" title="模型训练"></a>模型训练</h2><p><em>后补</em></p><h2 id="模型检测-3"><a href="#模型检测-3" class="headerlink" title="模型检测"></a>模型检测</h2><p><em>后补</em></p><h1 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h1><h2 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h2><p>在GoogLeNet中，最新的改进是新加入了基本卷积块<em>Inception</em>块。</p><p><strong>Inception</strong>块有四条并行分支路径，前三条路径使用的卷积核大小为$1\times1$、$3\times3$和$5\times5$，从不同空间大小中提取信息。中间的两条路径在输入上执行$1\times1$卷积，以减少通道数，从而降低模型的复杂性。第四条路径使用$3\times3$最大汇聚层，然后使用$1\times1$卷积层来改变通道数。</p><p>这四条路径都使用合适的填充来确保输入与输出的高和宽一致，这样才能将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。</p><p>Inception的架构为：</p><div align="center"><img src = "https://s2.loli.net/2022/04/17/nGbp3cWkMoI7mLS.png" width="80%"><br>Inception块架构</div><p>Inception块定义为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 支路一</span></span><br><span class="line">        self.b1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU())</span><br><span class="line">        <span class="comment"># 支路二</span></span><br><span class="line">        self.b2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU())</span><br><span class="line">        <span class="comment"># 支路三</span></span><br><span class="line">        self.b3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU())</span><br><span class="line">        <span class="comment"># 支路四</span></span><br><span class="line">        self.b4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU())</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output1 = self.b1(x)</span><br><span class="line">        output2 = self.b2(x)</span><br><span class="line">        output3 = self.b3(x)</span><br><span class="line">        output4 = self.b4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [output1, output2, output3, output4]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><h2 id="GoogLeNet模型"><a href="#GoogLeNet模型" class="headerlink" title="GoogLeNet模型"></a>GoogLeNet模型</h2><p>GoogLeNet是由一些基本的卷积核和9个Inception块进行卷积操作后连接一个全局平均汇聚层，最后再连接一个全连接层完成输出。</p><p>GoogLeNet的网络框架为：</p><div align="center"><img src = "https://s2.loli.net/2022/04/17/X7wthkvlcS1O3pZ.png" width="25%"><br>GoogLeNet的网络框架</div><p>基于pytorch实现GoogLeNet网络的模型搭建如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GoogLeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(GoogLeNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.m1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.m2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.m3 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">            Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.m4 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">            Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.m5 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">            Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">            nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Flatten())</span><br><span class="line">        </span><br><span class="line">        self.googlenet = nn.Sequential(self.m1, self.m2, self.m3, self.m4, self.m5, nn.Linear(<span class="number">1024</span>, num_classes))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.googlenet(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="模型检验-4"><a href="#模型检验-4" class="headerlink" title="模型检验"></a>模型检验</h2><p>构建一个高度和宽度为224的单通道数据样本，观察每个层输出的形状</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">in_channels = <span class="number">3</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">X = torch.randn(size=(<span class="number">1</span>, in_channels, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">net = GoogLeNet(in_channels, num_classes)</span><br><span class="line"><span class="built_in">print</span>(net(X))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net.googlenet:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape: \t&#x27;</span>,X.shape)</span><br></pre></td></tr></table></figure><p>结果为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.0278,  0.0170,  0.0201,  0.0070,  0.0244,  0.0257,  0.0028, -0.0330,</span><br><span class="line">         -0.0201, -0.0199]], grad_fn=&lt;AddmmBackward0&gt;)</span><br><span class="line">Sequential output shape:  torch.Size([1, 64, 56, 56])</span><br><span class="line">Sequential output shape:  torch.Size([1, 192, 28, 28])</span><br><span class="line">Sequential output shape:  torch.Size([1, 480, 14, 14])</span><br><span class="line">Sequential output shape:  torch.Size([1, 832, 7, 7])</span><br><span class="line">Sequential output shape:  torch.Size([1, 1024])</span><br><span class="line">Linear output shape:          torch.Size([1, 10])</span><br></pre></td></tr></table></figure></p><p>Inception块相当于⼀个有4条路径的⼦⽹络。它通过不同窗口形状的卷积层和最⼤汇聚层来并⾏抽取信息，并使⽤$1\times1$卷积层减少每像素级别上的通道维数从而降低模型复杂度。<br>GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之⽐是在ImageNet数据集上通过⼤量的实验得来的。<br>GoogLeNet和它的后继者们⼀度是ImageNet上最有效的模型之⼀：它以较低的计算复杂度提供了类似的测试精度。</p><p>另外：GoogLeNet还在第四个大模块的第1个(Inception4a)和第4个模块(Inception4d)后添加辅助分类器：其架构如图:</p><div align="center"><img src = "https://s2.loli.net/2022/04/17/4OropHvPXYqnz82.png" width="20%"><br>GoogLeNet的辅助分类器的网络框架</div><p>实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Assisant</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(Assisant, self).__init__()</span><br><span class="line">        self.feature = nn.Sequential(</span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>),</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">128</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, num_classes))</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.feature(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="模型训练-4"><a href="#模型训练-4" class="headerlink" title="模型训练"></a>模型训练</h2><p><em>后补</em></p><h2 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h2><p><em>后补</em></p><h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo教程</title>
      <link href="/2022/03/28/teach/hexo/"/>
      <url>/2022/03/28/teach/hexo/</url>
      
        <content type="html"><![CDATA[<h1 id="下载Git"><a href="#下载Git" class="headerlink" title="下载Git"></a>下载Git</h1><p>前往<a href="https://git-scm.com/downloads">官网</a>下载Git，并安装。<br><a href="https://blog.csdn.net/mukes/article/details/115693833">参考</a></p><h1 id="下载nodejs"><a href="#下载nodejs" class="headerlink" title="下载nodejs"></a>下载nodejs</h1><p>前往<a href="https://nodejs.org/en/">官网</a>下载nodejs，并安装。<br>参考：<br><a href="https://blog.csdn.net/weixin_58988988/article/details/126184356?spm=1001.2101.3001.6650.16">链接1</a><br><a href="https://ymjin.blog.csdn.net/article/details/121788104?spm=1001.2101.3001.6661.1">链接2</a></p><p>直接将以前的粘贴过来<br>执行命令</p><blockquote><p>渲染<br><code>npm install hexo-renderer-pug hexo-renderer-stylus --save</code><br>搜索<br><code>npm install hexo-generator-search --save</code><br>Mathjax<br><code>npm uninstall hexo-renderer-marked --save</code><br><code>npm install hexo-renderer-kramed --save</code><br>字数统计<br><code>npm install hexo-wordcount --save</code><br>hexo d出错，安装插件<br><code>npm install hexo-deployer-git --save</code></p></blockquote><p>第一次<code>hexo clean</code>,<code>hexo g</code>,<code>hexo d</code>时，不要在管理员命令行进行。<br>直接运行生成<code>.deploy_git</code></p><p><a href="https://zhuanlan.zhihu.com/p/102592286">参考教程</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/02/15/other/hello-world/"/>
      <url>/2022/02/15/other/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.<br>$1 \times 1$</p><script type="math/tex; mode=display">\begin{bmatrix}    0 & 0 & 0\\\\    0 & 1 & 0\\\\    0 & 0 & 0\\\\\end{bmatrix}</script><script type="math/tex; mode=display">\begin{pmatrix}0&1&1\\\\1&1&0\\\\1&0&1\\\\\end{pmatrix}</script><script type="math/tex; mode=display">\begin{pmatrix}x & y\\\\z & t\end{pmatrix}</script><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><hr><p>附上链接：<br><a href="https://github.com/hexojs/hexo/issues">vdskl</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
